{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc7a9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import optuna\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6db786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Sets seeds and forces deterministic algorithms.\n",
    "    \"\"\"\n",
    "    print(f\"--- Setting Global Seed: {seed} ---\")\n",
    "    \n",
    "    # 1. Set Env Var for Deterministic Algorithms (Must be before torch usage)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    \n",
    "    # 2. Python & Numpy\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 3. PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    \n",
    "    # 4. Force Deterministic Algorithms\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # New in PyTorch 1.8+ - throws error if an operation is non-deterministic\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except AttributeError:\n",
    "        pass # Older pytorch versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d491c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segmentation(df, y_label, window_size = 100, stride = 50):\n",
    "    '''\n",
    "    Segments the data into the same length and detach the whole dataset into X and y.\n",
    "    \n",
    "    df: data frame that contains all covariates and response variables\n",
    "    y_label: the column name of the response variable that we want to predict\n",
    "    window_size: the length of time included in a single data point\n",
    "    stride: The interval between two closest segmented data point\n",
    "    '''\n",
    "    j = df.columns.get_loc(y_label)\n",
    "    data = df.to_numpy()\n",
    "    n = len(data)\n",
    "    X = []\n",
    "    y = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    while start <= n - window_size:\n",
    "        end = start + window_size - 1\n",
    "        if data[start][j] == data[end][j] and data[start][0] + 0.01 > data[end][0] and data[start][j]!=0:\n",
    "            X.append(data[start:(end+1),1:-7])\n",
    "            y.append(data[start][j])\n",
    "            start += stride\n",
    "        else:\n",
    "            while start + window_size - 1 < n:\n",
    "                if data[start][j] != data[start+1][j]:\n",
    "                    break\n",
    "                start += 1\n",
    "            start += 1\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e1aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Returns the total number of trainable parameters in the model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "def train_model(model, data_loader, criterion, optimizer, num_epochs, scheduler=None, print_every_n_batches=100):\n",
    "    \"\"\"\n",
    "    Trains the model and prints the parameter count and running loss periodically.\n",
    "    Accepts an optional scheduler.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nNumber of model parameters is: {count_parameters(model)}\")\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % print_every_n_batches == 0:\n",
    "                avg_loss = running_loss / print_every_n_batches\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}] | Batch [{i+1}/{len(data_loader)}] | Running Loss: {avg_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "                running_loss = 0.0\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    print(\"\\nFinished Training.\")\n",
    "    return model\n",
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Tests the trained model and prints the parameter count and final accuracy.\n",
    "    \"\"\"\n",
    "    print(f\"\\nNumber of model parameters is: {count_parameters(model)}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_test = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
    "            y_test = np.append(y_test, labels.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "        # Print the evaluation metrics\n",
    "        print(\"Accuracy:\", f\"{accuracy:.4f}\")\n",
    "        print(\"Precision:\", f\"{precision:.4f}\")\n",
    "        print(\"Recall:\", f\"{recall:.4f}\")\n",
    "        print(\"F1 Score:\", f\"{f1:.4f}\")\n",
    "        print(f\"\\nTest accuracy of model: {accuracy*100:.2f}%\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # plot the confusion matrix\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "        plt.xticks(np.arange(5)+0.5, ['Relaxing', 'Coffee time', 'Early morning', 'Cleanup', 'Sandwich time'], rotation=90)\n",
    "        plt.yticks(np.arange(5)+0.5, ['Relaxing', 'Coffee time', 'Early morning', 'Cleanup', 'Sandwich time'], rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentations:\n",
    "    @staticmethod\n",
    "    def reverse(x):\n",
    "        \"\"\"\n",
    "        Reverses time dim.\n",
    "        Input: (B, C, L)\n",
    "        \"\"\"\n",
    "        return torch.flip(x, dims=[-1])\n",
    "\n",
    "    @staticmethod\n",
    "    def permute(x, segments=4):\n",
    "        \"\"\"\n",
    "        Splits time series into segments and shuffles them randomly.\n",
    "        \n",
    "        CRITICAL FOR MULTI-SENSOR DATA:\n",
    "        We shuffle the segments of ALL channels (C) synchronously.\n",
    "        If we shuffled channel 0 differently from channel 1, we would destroy\n",
    "        the inter-feature correlations (e.g., the relationship between \n",
    "        accelerometer and gyroscope).\n",
    "        \"\"\"\n",
    "        B, C, L = x.shape\n",
    "        segment_len = L // segments\n",
    "        effective_len = segment_len * segments\n",
    "        x_trimmed = x[:, :, :effective_len]\n",
    "        x_reshaped = x_trimmed.view(B, C, segments, segment_len)\n",
    "        rand_inds = torch.argsort(torch.rand(B, segments, device=x.device), dim=1)\n",
    "        expanded_inds = rand_inds.view(B, 1, segments, 1).expand(B, C, segments, segment_len)\n",
    "        x_permuted = torch.gather(x_reshaped, 2, expanded_inds)\n",
    "        return x_permuted.reshape(B, C, effective_len)\n",
    "\n",
    "    @staticmethod\n",
    "    def time_warp(x, sigma=0.2, num_knots=4):\n",
    "        \"\"\"\n",
    "        Simulates time warping by stretching and squeezing time.\n",
    "        \n",
    "        CRITICAL FOR MULTI-SENSOR DATA:\n",
    "        We generate ONE warp flow per sample and apply it to ALL channels.\n",
    "        \"\"\"\n",
    "        B, C, L = x.shape\n",
    "        device = x.device\n",
    "        warped_batch = []\n",
    "        \n",
    "        for i in range(B):\n",
    "            ratio = np.random.uniform(0.5, 1.5)\n",
    "            new_len = int(L * ratio)\n",
    "            signal_tensor = x[i].unsqueeze(0) \n",
    "            warped = F.interpolate(signal_tensor, size=new_len, mode='linear', align_corners=False)\n",
    "            if new_len > L:\n",
    "                start = np.random.randint(0, new_len - L)\n",
    "                restored = warped[:, :, start:start+L]\n",
    "            else:\n",
    "                padding = L - new_len\n",
    "                restored = F.pad(warped, (0, padding), \"constant\", 0)\n",
    "            warped_batch.append(restored.squeeze(0))\n",
    "            \n",
    "        return torch.stack(warped_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f938093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ssl_batch(x_batch):\n",
    "    \"\"\"\n",
    "    Returns batch augmented with binary labels for Multi-Task Learning.\n",
    "    Returns:\n",
    "        x_aug: (4*B, C, L)\n",
    "        y_rev: (4*B, 1)\n",
    "        y_perm: (4*B, 1)\n",
    "        y_warp: (4*B, 1)\n",
    "    \"\"\"\n",
    "    B, C, L = x_batch.shape\n",
    "    orig = x_batch.clone()\n",
    "    rev = Augmentations.reverse(x_batch)\n",
    "    perm = Augmentations.permute(x_batch)\n",
    "    warp = Augmentations.time_warp(x_batch)\n",
    "    \n",
    "    x_combined = torch.cat([orig, rev, perm, warp], dim=0)\n",
    "    l_rev = torch.cat([\n",
    "        torch.zeros(B), # Orig\n",
    "        torch.ones(B),  # Rev\n",
    "        torch.zeros(B), # Perm \n",
    "        torch.zeros(B)  # Warp \n",
    "    ]).unsqueeze(1)\n",
    "    l_perm = torch.cat([\n",
    "        torch.zeros(B),\n",
    "        torch.zeros(B),\n",
    "        torch.ones(B),  # Perm\n",
    "        torch.zeros(B)\n",
    "    ]).unsqueeze(1)\n",
    "    l_warp = torch.cat([\n",
    "        torch.zeros(B),\n",
    "        torch.zeros(B),\n",
    "        torch.zeros(B),\n",
    "        torch.ones(B)   # Warp\n",
    "    ]).unsqueeze(1)\n",
    "    idx = torch.randperm(x_combined.size(0))\n",
    "    return x_combined[idx], l_rev[idx], l_perm[idx], l_warp[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0449b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_S1 = pd.read_csv(\"S1.csv\")\n",
    "df_S2 = pd.read_csv(\"S2.csv\")\n",
    "df_S3 = pd.read_csv(\"S3.csv\")\n",
    "df_S4 = pd.read_csv(\"S4.csv\")\n",
    "X1_test, y1_test = data_segmentation(df_S1, \"HL_Activity\")\n",
    "X2_test, y2_test = data_segmentation(df_S2, \"HL_Activity\")\n",
    "X3_test, y3_test = data_segmentation(df_S3, \"HL_Activity\")\n",
    "X4_test, y4_test = data_segmentation(df_S4, \"HL_Activity\")\n",
    "y1_test -= 101\n",
    "y2_test -= 101\n",
    "y3_test -= 101\n",
    "y4_test -= 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6f5d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X1_test = torch.tensor(X1_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X2_test = torch.tensor(X2_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X3_test = torch.tensor(X3_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X4_test = torch.tensor(X4_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y1_test = torch.tensor(y1_test).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y2_test = torch.tensor(y2_test).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y3_test = torch.tensor(y3_test).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y4_test = torch.tensor(y4_test).long()\n"
     ]
    }
   ],
   "source": [
    "X1_test = torch.tensor(X1_test).float()\n",
    "X2_test = torch.tensor(X2_test).float()\n",
    "X3_test = torch.tensor(X3_test).float()\n",
    "X4_test = torch.tensor(X4_test).float()\n",
    "y1_test = torch.tensor(y1_test).long()\n",
    "y2_test = torch.tensor(y2_test).long()\n",
    "y3_test = torch.tensor(y3_test).long()\n",
    "y4_test = torch.tensor(y4_test).long()\n",
    "X = torch.cat((X1_test, X2_test, X3_test, X4_test), dim = 0)\n",
    "y = torch.cat((y1_test, y2_test, y3_test, y4_test), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12bdb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard ResNet Basic Block adapted for 1D.\n",
    "    Structure: Conv3x3 -> BN -> ReLU -> Conv3x3 -> BN -> Add -> ReLU\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # If dimensions change (stride > 1 or in != out), we need a 1x1 projection\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim=128):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, 1) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class ResNet_SSL(nn.Module):\n",
    "    \"\"\"\n",
    "    A lightweight ResNet-8 (3 Stages, 1 block each).\n",
    "    Total layers = Stem + 3*2 (blocks) + FC = ~8 layers\n",
    "    Max Channels = 128\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResNet_SSL, self).__init__()\n",
    "        self.in_planes = 32 # Start smaller\n",
    "        \n",
    "        # 1. Stem\n",
    "        self.initial_bn = nn.BatchNorm1d(in_channels)\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=5, stride=2, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 2. Layers (Only 3 layers, 1 block each)\n",
    "        # Structure: [1, 1, 1]\n",
    "        self.layer1 = self._make_layer(BasicBlock1D, 32,  blocks=1, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock1D, 64,  blocks=1, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock1D, 128, blocks=1, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # 3. SSL Heads (Connected to 128 features)\n",
    "        self.feature_dim = 128\n",
    "        self.head_reverse = nn.Linear(128, 1)\n",
    "        self.head_permute = nn.Linear(128, 1)\n",
    "        self.head_warp    = nn.Linear(128, 1)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = []\n",
    "        # First block handles stride and expansion\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        # Subsequent blocks (if any)\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.get_embedding(x)\n",
    "        return self.head_reverse(features), self.head_permute(features), self.head_warp(features)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. Fine-Tuning Wrapper\n",
    "# ==========================================\n",
    "\n",
    "class DownstreamResNet(nn.Module):\n",
    "    def __init__(self, pretrained_encoder, num_classes=2):\n",
    "        super(DownstreamResNet, self).__init__()\n",
    "        self.encoder = pretrained_encoder\n",
    "        in_features = pretrained_encoder.feature_dim\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder.get_embedding(x)\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab58011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Phase 1: Multi-Head SSL Pre-Training (ResNet-18) ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# set_seed(503)\n",
    "# A. Generate Mock Data (High Dimensional)\n",
    "N_SAMPLES = X.shape[0]\n",
    "# Important: With 4 downsampling stages (stride 2), signal length reduces by 2^5 = 32 approx.\n",
    "# Length 128 -> 4. Valid. If length is too small, ResNet crashes.\n",
    "SEQ_LEN = X.shape[1]\n",
    "CHANNELS = X.shape[2]\n",
    "\n",
    "\n",
    "\n",
    "dataset = TensorDataset(X.transpose(1,2), y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# -----------------------------------\n",
    "# B. SSL Pre-Training (ResNet-18)\n",
    "# -----------------------------------\n",
    "print(\"\\n--- Phase 1: Multi-Head SSL Pre-Training (ResNet-18) ---\")\n",
    "\n",
    "ssl_model = ResNet_SSL(in_channels=CHANNELS).to(device)\n",
    "optimizer = optim.Adam(ssl_model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "\n",
    "EPOCHS_SSL = 0\n",
    "\n",
    "ssl_model.train()\n",
    "for epoch in range(EPOCHS_SSL):\n",
    "    total_loss = 0\n",
    "    for x_batch, _ in loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        \n",
    "        aug_x, l_rev, l_perm, l_warp = generate_ssl_batch(x_batch)\n",
    "        aug_x = aug_x.to(device)\n",
    "        l_rev, l_perm, l_warp = l_rev.to(device), l_perm.to(device), l_warp.to(device)\n",
    "        \n",
    "        pred_rev, pred_perm, pred_warp = ssl_model(aug_x)\n",
    "        \n",
    "        loss = (criterion(pred_rev, l_rev.float()) + \n",
    "                criterion(pred_perm, l_perm.float()) + \n",
    "                criterion(pred_warp, l_warp.float()))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    # print(f\"Epoch [{epoch+1}/{EPOCHS_SSL}] SSL Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting Global Seed: 503 ---\n",
      "\n",
      "Model Architecture:\n",
      "DownstreamResNet(\n",
      "  (encoder): ResNet_SSL(\n",
      "    (initial_bn): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1): Conv1d(124, 32, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
      "    (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock1D(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock1D(\n",
      "        (conv1): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock1D(\n",
      "        (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "    (head_reverse): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (head_permute): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (head_warp): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "Number of model parameters is: 131008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_133896\\4075048237.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_133896\\4075048237.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_133896\\4075048237.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_133896\\4075048237.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] | Batch [100/515] | Running Loss: 1.1591 | LR: 0.000100\n",
      "Epoch [1/1] | Batch [200/515] | Running Loss: 0.8638 | LR: 0.000100\n",
      "Epoch [1/1] | Batch [300/515] | Running Loss: 0.7132 | LR: 0.000100\n",
      "Epoch [1/1] | Batch [400/515] | Running Loss: 0.6674 | LR: 0.000100\n",
      "Epoch [1/1] | Batch [500/515] | Running Loss: 0.5859 | LR: 0.000100\n",
      "\n",
      "Finished Training.\n",
      "\n",
      "Number of model parameters is: 131008\n",
      "Accuracy: 0.4401\n",
      "Precision: 0.6250\n",
      "Recall: 0.4401\n",
      "F1 Score: 0.3795\n",
      "\n",
      "Test accuracy of model: 44.01%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwMAAAMVCAYAAAArrSilAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhv1JREFUeJzs3XdYlfX/x/HXAQVkD1GUVJwoiiutzD3SHDlzZOXI1NRym2k5S01za65yN6zM/FqamgNn7r23OHCBgIgg4/z+8NcpAg0VOML9fFzXuZLPfZ/7vA9353Be5zNuk9lsNgsAAACA4dhYuwAAAAAA1kEYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAABYxenTp1W3bl25ubnJZDJp+fLlaXr8CxcuyGQyacGCBWl63MysRo0aqlGjhrXLAPAMIQwAgIGdPXtWXbt2VaFCheTg4CBXV1dVrlxZU6ZM0b1799L1sdu3b6/Dhw9r1KhRWrx4sSpUqJCuj5eROnToIJPJJFdX1xR/j6dPn5bJZJLJZNL48eMf+/hXr17V8OHDdeDAgTSoFoCRZbN2AQAA61i5cqVatmwpe3t7tWvXTqVKldL9+/e1detWDRgwQEePHtWcOXPS5bHv3bunP//8Ux9//LHef//9dHmMAgUK6N69e8qePXu6HP+/ZMuWTdHR0fr111/VqlWrJNu+/fZbOTg4KCYm5omOffXqVY0YMUJ+fn4qW7Zsqu+3du3aJ3o8AFkXYQAADOj8+fNq06aNChQooA0bNihPnjyWbT169NCZM2e0cuXKdHv8mzdvSpLc3d3T7TFMJpMcHBzS7fj/xd7eXpUrV9b333+fLAx89913atiwoX7++ecMqSU6OlqOjo6ys7PLkMcDkHkwTAgADGjcuHGKiorS3LlzkwSBvxQpUkS9evWy/BwfH69PP/1UhQsXlr29vfz8/DR48GDFxsYmuZ+fn58aNWqkrVu36oUXXpCDg4MKFSqkRYsWWfYZPny4ChQoIEkaMGCATCaT/Pz8JD0YXvPXv/9p+PDhMplMSdr++OMPValSRe7u7nJ2dpa/v78GDx5s2f6wOQMbNmxQ1apV5eTkJHd3dzVp0kTHjx9P8fHOnDmjDh06yN3dXW5uburYsaOio6Mf/ov9l7Zt2+r3339XeHi4pW337t06ffq02rZtm2z/sLAw9e/fX4GBgXJ2dparq6vq16+vgwcPWvYJCgpSxYoVJUkdO3a0DDf663nWqFFDpUqV0t69e1WtWjU5Ojpafi//njPQvn17OTg4JHv+9erVk4eHh65evZrq5wogcyIMAIAB/frrrypUqJBefvnlVO3/7rvvaujQoSpfvrwmTZqk6tWra8yYMWrTpk2yfc+cOaPXX39dr7zyiiZMmCAPDw916NBBR48elSQ1b95ckyZNkiS98cYbWrx4sSZPnvxY9R89elSNGjVSbGysRo4cqQkTJqhx48batm3bI++3bt061atXTzdu3NDw4cPVt29fbd++XZUrV9aFCxeS7d+qVSvduXNHY8aMUatWrbRgwQKNGDEi1XU2b95cJpNJy5Yts7R99913Kl68uMqXL59s/3Pnzmn58uVq1KiRJk6cqAEDBujw4cOqXr265YN5iRIlNHLkSElSly5dtHjxYi1evFjVqlWzHCc0NFT169dX2bJlNXnyZNWsWTPF+qZMmSJvb2+1b99eCQkJkqTZs2dr7dq1mjZtmvLmzZvq5wogkzIDAAwlIiLCLMncpEmTVO1/4MABsyTzu+++m6S9f//+ZknmDRs2WNoKFChglmTevHmzpe3GjRtme3t7c79+/Sxt58+fN0syf/HFF0mO2b59e3OBAgWS1TBs2DDzP/9kTZo0ySzJfPPmzYfW/ddjzJ8/39JWtmxZc65cucyhoaGWtoMHD5ptbGzM7dq1S/Z477zzTpJjNmvWzOzl5fXQx/zn83BycjKbzWbz66+/bq5du7bZbDabExISzD4+PuYRI0ak+DuIiYkxJyQkJHse9vb25pEjR1radu/eney5/aV69epmSeZZs2aluK169epJ2tasWWOWZP7ss8/M586dMzs7O5ubNm36n88RQNZAzwAAGExkZKQkycXFJVX7r1q1SpLUt2/fJO39+vWTpGRzCwICAlS1alXLz97e3vL399e5c+eeuOZ/+2uuwf/+9z8lJiam6j4hISE6cOCAOnToIE9PT0t76dKl9corr1ie5z+99957SX6uWrWqQkNDLb/D1Gjbtq2CgoJ07do1bdiwQdeuXUtxiJD0YJ6Bjc2DP80JCQkKDQ21DIHat29fqh/T3t5eHTt2TNW+devWVdeuXTVy5Eg1b95cDg4Omj17dqofC0DmRhgAAINxdXWVJN25cydV+1+8eFE2NjYqUqRIknYfHx+5u7vr4sWLSdrz58+f7BgeHh66ffv2E1acXOvWrVW5cmW9++67yp07t9q0aaMff/zxkcHgrzr9/f2TbStRooRu3bqlu3fvJmn/93Px8PCQpMd6Lg0aNJCLi4t++OEHffvtt6pYsWKy3+VfEhMTNWnSJBUtWlT29vbKmTOnvL29dejQIUVERKT6MX19fR9rsvD48ePl6empAwcOaOrUqcqVK1eq7wsgcyMMAIDBuLq6Km/evDpy5Mhj3e/fE3gfxtbWNsV2s9n8xI/x13j2v+TIkUObN2/WunXr9Pbbb+vQoUNq3bq1XnnllWT7Po2neS5/sbe3V/PmzbVw4UL98ssvD+0VkKTRo0erb9++qlatmr755hutWbNGf/zxh0qWLJnqHhDpwe/ncezfv183btyQJB0+fPix7gsgcyMMAIABNWrUSGfPntWff/75n/sWKFBAiYmJOn36dJL269evKzw83LIyUFrw8PBIsvLOX/7d+yBJNjY2ql27tiZOnKhjx45p1KhR2rBhgzZu3Jjisf+q8+TJk8m2nThxQjlz5pSTk9PTPYGHaNu2rfbv3687d+6kOOn6L0uXLlXNmjU1d+5ctWnTRnXr1lWdOnWS/U5SG8xS4+7du+rYsaMCAgLUpUsXjRs3Trt3706z4wN4thEGAMCAPvzwQzk5Oendd9/V9evXk20/e/aspkyZIunBMBdJyVb8mThxoiSpYcOGaVZX4cKFFRERoUOHDlnaQkJC9MsvvyTZLywsLNl9/7r41r+XO/1Lnjx5VLZsWS1cuDDJh+sjR45o7dq1lueZHmrWrKlPP/1U06dPl4+Pz0P3s7W1Tdbr8NNPP+nKlStJ2v4KLSkFp8c1cOBABQcHa+HChZo4caL8/PzUvn37h/4eAWQtXHQMAAyocOHC+u6779S6dWuVKFEiyRWIt2/frp9++kkdOnSQJJUpU0bt27fXnDlzFB4erurVq2vXrl1auHChmjZt+tBlK59EmzZtNHDgQDVr1kw9e/ZUdHS0Zs6cqWLFiiWZQDty5Eht3rxZDRs2VIECBXTjxg3NmDFDzz33nKpUqfLQ43/xxReqX7++KlWqpE6dOunevXuaNm2a3NzcNHz48DR7Hv9mY2OjTz755D/3a9SokUaOHKmOHTvq5Zdf1uHDh/Xtt9+qUKFCSfYrXLiw3N3dNWvWLLm4uMjJyUkvvviiChYs+Fh1bdiwQTNmzNCwYcMsS53Onz9fNWrU0JAhQzRu3LjHOh6AzIeeAQAwqMaNG+vQoUN6/fXX9b///U89evTQRx99pAsXLmjChAmaOnWqZd+vv/5aI0aM0O7du9W7d29t2LBBgwYN0pIlS9K0Ji8vL/3yyy9ydHTUhx9+qIULF2rMmDF67bXXktWeP39+zZs3Tz169NCXX36patWqacOGDXJzc3vo8evUqaPVq1fLy8tLQ4cO1fjx4/XSSy9p27Ztj/1BOj0MHjxY/fr105o1a9SrVy/t27dPK1euVL58+ZLslz17di1cuFC2trZ677339MYbb2jTpk2P9Vh37tzRO++8o3Llyunjjz+2tFetWlW9evXShAkTtGPHjjR5XgCeXSbz48yCAgAAAJBl0DMAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAg+KiY3gi+y5GWrsEZKAAX1drl4AMdDc23tolIAM52fNRAMiqHFLx8qZnAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijCQQYKCgmQymRQeHp5mxxw+fLjKli2bZscDAACAsRAGUqlDhw4ymUwymUzKnj27ChYsqA8//FAxMTFWq6l///5av3691R4/Kzh+aJ++GNJH3drU1xt1K2r3tqAk23dt3aDRH72vzi3q6I26FXXh7Mlkx1i/cplG9u+qd5rW0Bt1K+pu1J0Mqh7pZcl336r+K7VUsVyg3mzTUocPHbJ2SUgDi+Z9pXfeaqU6VSqqQe2qGtj3A128cD7JPpcvBeujfj3VoFYV1an6gj4Z2FdhobesVDHSA69vY+F8/zfCwGN49dVXFRISonPnzmnSpEmaPXu2hg0bZrV6nJ2d5eXlZbXHzwpiY+4pf6Fieuf9Dx+yPUb+pcrojXfff/gxYmNUpkIlNWnTIZ2qREZa/fsqjR83Rl2799CSn36Rv39xdevaSaGhodYuDU9p/97datHqDc1Z+L2mzPxK8fHx6t29s+7di5Yk3bsXrd49usgkk6bNnqfZ875RXFycBvTuocTERCtXj7TA69tYON+pQxh4DPb29vLx8VG+fPnUtGlT1alTR3/88YckKTExUWPGjFHBggWVI0cOlSlTRkuXLn3osUJDQ/XGG2/I19dXjo6OCgwM1Pfff2/ZfvPmTfn4+Gj06NGWtu3bt8vOzs7SG/DvYUIdOnRQ06ZNNX78eOXJk0deXl7q0aOH4uLiLPuEhISoYcOGypEjhwoWLKjvvvtOfn5+mjx5chr9ljKXsi9UVuuO3VSxSs0Ut1et00At3uqswHIvPPQYDZq3VZM2HVS0RGB6lYkMtHjhfDV/vZWaNmuhwkWK6JNhI+Tg4KDly362dml4SpO+nKOGjZupUOEiKlqsuD4ZMUrXr4XoxLFjkqRDB/br2tUr+mTEKBUuWkyFixbTkBGjdeLYUe3dvdPK1SMt8Po2Fs536hAGntCRI0csH84lacyYMVq0aJFmzZqlo0ePqk+fPnrrrbe0adOmFO8fExOj559/XitXrtSRI0fUpUsXvf3229q1a5ckydvbW/PmzdPw4cO1Z88e3blzR2+//bbef/991a5d+6F1bdy4UWfPntXGjRu1cOFCLViwQAsWLLBsb9euna5evaqgoCD9/PPPmjNnjm7cuJF2vxggE4u7f1/Hjx3VS5VetrTZ2NjopZde1qGD+61YGdLD3TsPhvS5urlJenD+TSaTsv//+7ok2dnby8bGRgf377NKjUg7vL6NhfOdetmsXUBm8ttvv8nZ2Vnx8fGKjY2VjY2Npk+frtjYWI0ePVrr1q1TpUqVJEmFChXS1q1bNXv2bFWvXj3ZsXx9fdW/f3/Lzx988IHWrFmjH3/8US+88OBb6AYNGqhz58568803VaFCBTk5OWnMmDGPrNHDw0PTp0+Xra2tihcvroYNG2r9+vXq3LmzTpw4oXXr1mn37t2qUKGCJOnrr79W0aJFH3nM2NhYxcbGJmm7HxsrO3v7//6lAZnI7fDbSkhISDb8zsvLS+fPn7NSVUgPiYmJmjx+rEqXLafCRR68B5YsXUYOOXJoxpQJeu/93jLLrJlTJykhIUGht25auWI8LV7fxsL5Tj16Bh5DzZo1deDAAe3cuVPt27dXx44d1aJFC505c0bR0dF65ZVX5OzsbLktWrRIZ8+eTfFYCQkJ+vTTTxUYGChPT085OztrzZo1Cg4OTrLf+PHjFR8fr59++knffvut7P/jA3jJkiVla2tr+TlPnjyWb/5PnjypbNmyqXz58pbtRYoUkYeHxyOPOWbMGLm5uSW5zZ8x8ZH3AYBn2YTPP9O5s6c1csx4S5uHh6c+GztRW7dsUu0qFVW32ku6c+eO/IsHyMaGP5cAsiZ6Bh6Dk5OTihQpIkmaN2+eypQpo7lz56pUqVKSpJUrV8rX1zfJfR724f2LL77QlClTNHnyZAUGBsrJyUm9e/fW/fv3k+x39uxZXb16VYmJibpw4YICAx89Lj179uxJfjaZTE898W3QoEHq27dvkrZj12IfsjeQeXm4e8jW1jbZ5LLQ0FDlzJnTSlUhrU34/DNt27JJM75eqFy5fZJse7FSZS1dsVrht2/LNputXFxc1eiVasrrW99K1SKt8Po2Fs536vFVxxOysbHR4MGD9cknnyggIED29vYKDg5WkSJFktzy5cuX4v23bdumJk2a6K233lKZMmVUqFAhnTp1Ksk+9+/f11tvvaXWrVvr008/1bvvvvtU4/v9/f0VHx+v/fv/Hit35swZ3b59+5H3s7e3l6ura5IbQ4SQFWW3s1OJgJLaueNPS1tiYqJ27vxTpcuUs2JlSAtms1kTPv9Mmzau17TZ85TX97mH7uvu4SEXF1ft2bVDt8PCVKV6yosMIPPg9W0snO/Uo2fgKbRs2VIDBgzQ7Nmz1b9/f/Xp00eJiYmqUqWKIiIitG3bNrm6uqp9+/bJ7lu0aFEtXbpU27dvl4eHhyZOnKjr168rICDAss/HH3+siIgITZ06Vc7Ozlq1apXeeecd/fbbb09Ub/HixVWnTh116dJFM2fOVPbs2dWvXz/lyJFDJpPpiX8PmVnMvWhdu3rJ8vPNa1d14exJObu4KWcuH0VFRujWzWu6/f/rjIdcuihJcvfwkrvng28WwsNuKfx2qOU4l86fkYOjo3J6+8jZ1S2DnxGe1tvtO2rI4IEqWbKUSgWW1jeLF+revXtq2qy5tUvDUxr/+af64/dVGjtpmhwdHS3zAJydXWTv4CBJ+u1/v8ivYCG5e3joyKGDmjx+jFq/2U4F/Apas3SkEV7fxsL5Th3CwFPIli2b3n//fY0bN07nz5+Xt7e3xowZo3Pnzsnd3V3ly5fX4MGDU7zvJ598onPnzqlevXpydHRUly5d1LRpU0VEREh6cMXiyZMna+PGjXJ1dZUkLV68WGXKlNHMmTPVrVu3J6p50aJF6tSpk6pVqyYfHx+NGTNGR48elcP//yE0mnOnjuvTAe9Zfl48e5IkqdorDdVtwHDt3bFZs8aPtGyfOvpjSVKLtzrr9XZdJEnrflumn7/5yrLPiH4P2t/rP1TV676W7s8BaevV+g10OyxMM6ZP1a1bN+VfvIRmzP5aXnQrZ3q//PSDJKlH5w5J2j8e/pkaNm4mSQq+eF6zpk9SZESE8uT1VftOXdTmzeRf6CBz4vVtLJzv1DGZzWaztYuA9Vy+fFn58uXTunXrHrlk6b/tuxiZjlXhWRPg62rtEpCB7sbGW7sEZCAne74XBLIqh1S8vHkHMJgNGzYoKipKgYGBCgkJ0Ycffig/Pz9Vq1bN2qUBAAAggxEGDCYuLk6DBw/WuXPn5OLiopdfflnffvttslWIAAAAkPUxTAhPhGFCxsIwIWNhmJCxMEwIyLpSM0yIpUUBAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAok9lsNlu7CGQ+MfHWrgAZKSI6ztolIAMNXXvK2iUgA01pWtLaJSADJSbysc9IHO1M/7kPPQMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMLAI8yZM0f58uWTjY2NJk+e/NC2jNKhQwc1bdo0Qx8TAAAAWZfJbDabrV1EWrt27ZpGjRqllStX6sqVK8qVK5fKli2r3r17q3bt2qk6RmRkpHLmzKmJEyeqRYsWcnNzU3x8fLI2R0fHNK//woULKliwoPbv36+yZcta2iMiImQ2m+Xu7p7mj/m4YuKtXUHGWvLdt1o4f65u3bqpYv7F9dHgIQosXdraZWWYiOg4a5eQLpYvXaLlP/+gayFXJUkFCxVR+07v6aXKVSVJVy4Ha8aU8Tp0YL/i4u7rxUpV1Kv/IHl65bRm2elu6NpT1i4hTbzqn1PlfF3l42Kn+wlmnQuN1rLD13U96r4kycsxu0Y3KJbifWf/eUn7rkRKkjxyZNeb5fPI39tJMfGJ2nExXL8cua7ELPLXc0rTktYuIUMZ/f08Mav8j/sfGtSrpZCrV5O1t2rdVoM+GWqFiqzD0c70n/tky4A6MtSFCxdUuXJlubu764svvlBgYKDi4uK0Zs0a9ejRQydOnEjVcYKDgxUXF6eGDRsqT548kqQjR44ka8tIbm5uGf6YkFb/vkrjx43RJ8NGKDCwjL5dvFDdunbS/35bLS8vL2uXh6fgnctHXd/vo+fyFZDMZq1e+T8N7v+B5n6zVD5586rf+11UuKi/Js+cK0maO2u6Pur7vmbN/042NnSsPuuKeTsq6GyYLty+J1uT1LRUbvWqWkDD157R/QSzwqLjNODXk0nuU7WQh+oW89LRa1GSJJOkD6rkV0RMvMZuPC+3HNnUsaKvEsxmLT9ywwrPCk+D93Pj+Ob7pUpMTLD8fOb0aXXr8o5eqVfPilU9m7LcX7Pu3bvLZDJp165datGihYoVK6aSJUuqb9++2rFjh2W/4OBgNWnSRM7OznJ1dVWrVq10/fp1SdKCBQsUGBgoSSpUqJBMJlOKbRcuXJAk/e9//1P58uXl4OCgQoUKacSIEYqP//ur8/DwcL377rvy9vaWq6uratWqpYMHDz70ORQsWFCSVK5cOZlMJtWoUUNS8mFCNWrU0AcffKDevXvLw8NDuXPn1ldffaW7d++qY8eOcnFxUZEiRfT7778nOf6RI0dUv359OTs7K3fu3Hr77bd169atJ/uFG8DihfPV/PVWatqshQoXKaJPho2Qg4ODli/72dql4SlVrlZDlSpXU778BZSvgJ86d++lHI6OOnrkoA4f3K9rIVc1eNgoFS5STIWLFNPg4aN08vhR7du909qlIxWmbg3WnxfDFRIZq8sRsVqw+4q8nOxUwCOHJMksKTI2PsmtbF4X7bkcqdiERElSgI+z8rjaa96uy7ocEaOj16K04ugN1SjsKVvTf3/jhmcL7+fG4enpqZw5vS23LZuDlC9ffj1f4QVrl/bMyVJhICwsTKtXr1aPHj3k5OSUbPtfw2sSExPVpEkThYWFadOmTfrjjz907tw5tW7dWpLUunVrrVu3TpK0a9cuhYSEqGXLlsna8uXLpy1btqhdu3bq1auXjh07ptmzZ2vBggUaNWqU5XFbtmypGzdu6Pfff9fevXtVvnx51a5dW2FhYSk+j127dkmS1q1bp5CQEC1btuyhz3nhwoXKmTOndu3apQ8++EDdunVTy5Yt9fLLL2vfvn2qW7eu3n77bUVHR0t6EExq1aqlcuXKac+ePVq9erWuX7+uVq1aPeZv2xji7t/X8WNH9VKlly1tNjY2eumll3Xo4H4rVoa0lpCQoPVrVynm3j2VCiyruPtxMplMym5nZ9nHzs5eNjY2OnRwnxUrxZPKkd1WknT3fkKK2/O7Oyi/Rw5tu3Db0lbIM4euRMToTuzf9zl6LUo5stsqr5t9+haMNMX7uXHFxd3Xqt9WqEmz5jIR4pPJUsOEzpw5I7PZrOLFiz9yv/Xr1+vw4cM6f/688uXLJ0latGiRSpYsqd27d6tixYqW7kJvb2/5+PhIUoptI0aM0EcffaT27dtLetBr8Omnn+rDDz/UsGHDtHXrVu3atUs3btyQvf2DPxzjx4/X8uXLtXTpUnXp0iVZfd7e3pbH++txHqZMmTL65JNPJEmDBg3S559/rpw5c6pz586SpKFDh2rmzJk6dOiQXnrpJU2fPl3lypXT6NGjLceYN2+e8uXLp1OnTqlYseTjZ2NjYxUbG5ukzWxrb3k+Wdnt8NtKSEhI1n3s5eWl8+fPWakqpKWzZ06p+ztv6v79+8qRw1GffTFFfoUKy93DQw4OOTRr2kR16dFLZrNZs6dPVkJCgkLpSct0TJJalfXRmVt3dTUyNsV9Khf00NXIGJ0LvWdpc3PIpsiYpOEhMvZBz6+rQ5b6E5rl8X5uXBvXr9edO3f0WpNm1i7lmZSlegZSOxf6+PHjypcvnyUISFJAQIDc3d11/Pjxx3rMgwcPauTIkXJ2drbcOnfurJCQEEVHR+vgwYOKioqSl5dXkn3Onz+vs2fPPtZjpaT0PyY92draysvLyzKcSZJy584tSbpx44al3o0bNyap5a/w9LB6xowZIzc3tyS3L8aOeeragWdB/gIFNffbnzVr/ndq0qKVRg//WBfOnZW7h6dGfD5B27cEqV61F9SgZiVF3YlUseIBsrHhm6XM5o1yeZTX1V5f7byc4vbsNia9kM9N286HZ2xhANLd8l+WqnKVqsqVK7e1S3kmZamvNYoWLSqTyZTqScJpISoqSiNGjFDz5s2TbXNwcFBUVJTy5MmjoKCgZNvTYlWg7NmzJ/nZZDIlafurOywxMdFS72uvvaaxY8cmO9bDJkUPGjRIffv2TdJmts36vQKS5OHuIVtbW4WGhiZpDw0NVc6cWXtFGaPInj27nsuXX5LkX6KkThw7qp+WfKMBg4fphZcqa8ny1QoPvy1bW1u5uLiqab3qylv3VStXjcfRpqyPAvO4aHzQeYXfS3kptPLPucoum0k7LoYnaY+IiZefZ44kba72D/50RhptWbVMjvdzY7p69Yp27vhT4ydNs3Ypz6wsFQY8PT1Vr149ffnll+rZs2eyeQPh4eFyd3dXiRIldOnSJV26dMnSO3Ds2DGFh4crICDgsR6zfPnyOnnypIoUKfLQ7deuXVO2bNnk5+eXqmPa/f8Y5YSElMe1Po3y5cvr559/lp+fn7JlS93pt7dPPiTIKH8Ds9vZqURASe3c8adq1a4j6UGw2rnzT7V54y0rV4f0kGhOVNz9+0na3N09JEl7d+/U7dthqly1pjVKwxNoU9ZHZX1dNXHTBYU+YoncygU9dPDqHUX9az7BubB7alDCWy72tpZ5AwG5nXUvLkEhDxluhGcT7+fGtGL5Mnl6eqlqterWLuWZlaWGCUnSl19+qYSEBL3wwgv6+eefdfr0aR0/flxTp05VpUqVJEl16tRRYGCg3nzzTe3bt0+7du1Su3btVL16dVWoUOGxHm/o0KFatGiRRowYoaNHj+r48eNasmSJZRx/nTp1VKlSJTVt2lRr167VhQsXtH37dn388cfas2dPisfMlSuXcuTIYZncGxER8XS/lH/o0aOHwsLC9MYbb2j37t06e/as1qxZo44dO6ZL+MgK3m7fUcuW/qgVy3/RubNn9dnI4bp3756aNkveG4TMZfb0STqwb49Crl7R2TOnHvy8d7deqd9QkrRqxS86evigrlwO1tpVv2rYoL5q+UY75fcraOXKkRpvlMujF/O7a+7Oy4qJS5SrfTa52mdT9n8N8/J2slPRnI4pDhE6di1KIZGx6ljxOT3nZq+A3E5qXDKXgs6GKd4g67VnJbyfG0tiYqL+t/wXNWrcNNVfgBpRlvvNFCpUSPv27dOoUaPUr18/hYSEyNvbW88//7xmzpwp6cHQmf/973/64IMPVK1aNdnY2OjVV1/VtGmP34VUr149/fbbbxo5cqTGjh2r7Nmzq3jx4nr33Xctj7Vq1Sp9/PHH6tixo27evCkfHx9Vq1bNMp7/37Jly6apU6dq5MiRGjp0qKpWrZriMKMnkTdvXm3btk0DBw5U3bp1FRsbqwIFCujVV19l3fSHeLV+A90OC9OM6VN169ZN+RcvoRmzv5YX3cqZ3u3bYRo9fLBCb92Uk7OLChcppvHTZqviiw9WGwm+eEFzvpysyMgI+eT11dsdu6hV23ZWrhqpVaOwpySpf42k4W3B7iv68x/DgSoXdFf4vTgdux6V7BhmSdO3BattuTwaWLOQYhMS9efFcK04yjUGMiPez41l547tuhZylbD3H7LkFYiR/owyTAgPZNUrECNlWeUKxEgdo12B2OiMcgViPJCaKxDzVTAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAok9lsNlu7CGQ+MfHWrgBAevGo+L61S0AGur17urVLAJBOHLL99z70DAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADCpbanZasWJFqg/YuHHjJy4GAAAAQMZJVRho2rRpqg5mMpmUkJDwNPUAAAAAyCCpCgOJiYnpXQcAAACADMacAQAAAMCgUtUz8G93797Vpk2bFBwcrPv37yfZ1rNnzzQpDAAAAED6euwwsH//fjVo0EDR0dG6e/euPD09devWLTk6OipXrlyEAQAAACCTeOxhQn369NFrr72m27dvK0eOHNqxY4cuXryo559/XuPHj0+PGgEAAACkg8cOAwcOHFC/fv1kY2MjW1tbxcbGKl++fBo3bpwGDx6cHjUCAAAASAePHQayZ88uG5sHd8uVK5eCg4MlSW5ubrp06VLaVgcAAAAg3Tz2nIFy5cpp9+7dKlq0qKpXr66hQ4fq1q1bWrx4sUqVKpUeNQIAAABIB4/dMzB69GjlyZNHkjRq1Ch5eHioW7duunnzpubMmZPmBQIAAABIHyaz2Wy2dhHIfGLirV0BgPTiUfF9a5eADHR793RrlwAgnTikYgyQoS461qFDBzVt2tTaZaQpPz8/TZ482dplAAAAIBN67DkDBQsWlMlkeuj2c+fOPVVBHTp00MKFC5O116tXT6tXr36qY2dFu3fvlpOTk7XLyPKWfPetFs6fq1u3bqqYf3F9NHiIAkuXtnZZSGNzv5qt9X+s1fnz52Tv4KCyZcupd9/+8itYyNql4Ql83LWBPnmvQZK2k+evqWzzz+Th6qgh3Rqq9kvFlc/HQ7duR+nXoEMaMeM3RUbFJDuWp5uTdv3wkXxze8in6gBFRN3LqKeBNMb7ubFwvv/bY4eB3r17J/k5Li5O+/fv1+rVqzVgwIA0KerVV1/V/Pnzk7TZ29s/8fESEhIeGWCeRXFxccqePft/7uft7Z0B1Rjb6t9Xafy4Mfpk2AgFBpbRt4sXqlvXTvrfb6vl5eVl7fKQhvbs3qXWb7ypkoGBSohP0LQpE/Ve505atmKlHB0drV0ensDRM1fV8L1plp/jExIlSXm83ZTH202DJv2i4+euKX8eT037uI3yeLup7YC5yY4za1hbHT59Vb65PTKsdqQ93s+NhfOdOo89TKhXr15Jbv3799e3336rkSNH6uTJk2lSlL29vXx8fJLcPDz+fgOeOHGiAgMD5eTkpHz58ql79+6KioqybF+wYIHc3d21YsUKBQQEyN7e3rIE6l8WLVokLy8vxcbGJmlv2rSp3n777RTrunDhgkwmk3788UdVrVpVOXLkUMWKFXXq1Cnt3r1bFSpUkLOzs+rXr6+bN29a7peYmKiRI0fqueeek729vcqWLZukl+Ov4/7www+qXr26HBwc9O2331qGNY0fP1558uSRl5eXevToobi4OMt9/z1MyGQy6euvv1azZs3k6OiookWLasWKFUmex4oVK1S0aFE5ODioZs2aWrhwoUwmk8LDw//75BjQ4oXz1fz1VmrarIUKFymiT4aNkIODg5Yv+9napSGNzZwzV02aNVeRIkXlX7y4Ro76XCEhV3X82FFrl4YnFJ+QqOuhdyy30PC7kqRjZ0P0Rv+vtWrzEZ2/fEubdp/S8Om/qkG1UrK1TfqnsXPLKnJzcdTkReut8RSQhng/NxbOd+qk2ZyB+vXr6+efM+aXa2Njo6lTp+ro0aNauHChNmzYoA8//DDJPtHR0Ro7dqy+/vprHT16VLly5UqyvWXLlkpISEjyQfnGjRtauXKl3nnnnUc+/rBhw/TJJ59o3759ypYtm9q2basPP/xQU6ZM0ZYtW3TmzBkNHTrUsv+UKVM0YcIEjR8/XocOHVK9evXUuHFjnT59OslxP/roI/Xq1UvHjx9XvXr1JEkbN27U2bNntXHjRi1cuFALFizQggULHlnfiBEj1KpVKx06dEgNGjTQm2++qbCwMEnS+fPn9frrr6tp06Y6ePCgunbtqo8//viRxzOyuPv3dfzYUb1U6WVLm42NjV566WUdOrjfipUhI0TduSNJcnVzs3IleFJF8nvr3NpROvbrcM0f1V75fB7+zb6ri4Mi78Yo4f97DySpeCEfDepcX+8OWaTERNbbyMx4PzcWznfqpVkYWLp0qTw9PdPkWL/99pucnZ2T3EaPHm3Z3rt3b9WsWVN+fn6qVauWPvvsM/34449JjhEXF6cZM2bo5Zdflr+/f7Iu/hw5cqht27ZJhiN98803yp8/v2rUqPHI+vr376969eqpRIkS6tWrl/bu3ashQ4aocuXKKleunDp16qSNGzda9h8/frwGDhyoNm3ayN/fX2PHjlXZsmWTTfzt3bu3mjdvroIFC1qWb/Xw8ND06dNVvHhxNWrUSA0bNtT69Y/+dqpDhw564403VKRIEY0ePVpRUVHatWuXJGn27Nny9/fXF198IX9/f7Vp00YdOnR45PFiY2MVGRmZ5PbvHpWs6nb4bSUkJCTrTvTy8tKtW7esVBUyQmJiosaNHa2y5cqraNFi1i4HT2D3kQvqMvQbNe7xpXqO/kF+vl5aN6+PnB2TDzv1cnfSoM71Ne/n7ZY2u+zZtHBMBw2evFyXrt3OyNKRDng/NxbOd+o90UXH/jn+3mw269q1a7p586ZmzJiRJkXVrFlTM2fOTNL2z6Cxbt06jRkzRidOnFBkZKTi4+MVExOj6Ohoy4d+Ozs7lf6PCSKdO3dWxYoVdeXKFfn6+mrBggXq0KHDf84v+Odxc+fOLUkKDAxM0nbjxg1JUmRkpK5evarKlSsnOUblypV18ODBJG0VKlRI9lglS5aUra2t5ec8efLo8OHDqa7PyclJrq6ulnpOnjypihUrJtn/hRdeeOTxxowZoxEjRiRp+3jIMH0ydPgj7wdkZqM/G6Gzp09rweLvrF0KntDabccs/z5y+qp2H76gk6tGqkXd8lq4/E/LNhcnB/0ytZuOnwvRZ7NXWto/7dlYJ89f15JVuzO0bgDISI8dBpo0aZLkw7KNjY28vb1Vo0YNFS9ePE2KcnJyUpEiRVLcduHCBTVq1EjdunXTqFGj5Onpqa1bt6pTp066f/++JQzkyJHjPz/UlytXTmXKlNGiRYtUt25dHT16VCtXrnzkfSQlmdj712P8uy0xMTHZ/f5LSqsC/XsScWqO/ST3eZRBgwapb9++SdrMtk8+oTsz8XD3kK2trUJDQ5O0h4aGKmfOnFaqCult9GcjtXlTkOYt/Ea5fXysXQ7SSETUPZ0JvqHC+f5eeMHZ0V4rvuyuO9Exat33K8XH//1eWb1iMZUqklfNdpeV9Pf7/eWNn2vs3DX6bNaqDK0fT4f3c2PhfKfeY4eB4cOHp0MZqbd3714lJiZqwoQJsrF5MMrp30OEHse7776ryZMn68qVK6pTp47y5cuXVqVKklxdXZU3b15t27ZN1atXt7Rv27btP7+RTw/+/v5atSrpH7Ddux/9rZe9vX2y1ZyMctGx7HZ2KhFQUjt3/KlatetIejB8ZOfOP9XmjbesXB3Smtls1phRn2rD+j80d8FiPfdc2r4fwLqcctip4HM5dW3lg2GTLk4O+nVGD8Xej9frvWcr9n7SN7Y3+n+tHPZ/f7nyfMkCmjPiLdXpNFnnLt0UMhfez42F8516jx0GbG1tFRISkmxCbmhoqHLlyqWEhISnLio2NlbXrl1L0pYtWzblzJlTRYoUUVxcnKZNm6bXXntN27Zt06xZs574sdq2bav+/fvrq6++0qJFi5629BQNGDBAw4YNU+HChVW2bFnNnz9fBw4c0Lfffpsuj/coXbt21cSJEzVw4EB16tRJBw4csExIzmzLr2aUt9t31JDBA1WyZCmVCiytbxYv1L1799S0WXNrl4Y0NvrTEfp91W+aPG2GnByddOv/VwVzdnGRg4ODlavD4xrTp5lWbj6s4KthypvLTZ+811AJiYn6cfVeuTg56LcZPZTDwU4dP14oVycHuTo9OMc3b0cpMdGs85eTjiv2cneWJJ04d43rDGRSvJ8bC+c7dR47DJjNKa+mEBsbKzs7u6cuSJJWr15tmUD7F39/f504cUJlypTRxIkTNXbsWA0aNEjVqlXTmDFj1K5duyd6LDc3N7Vo0UIrV65Mt6sT9+zZUxEREerXr59u3LihgIAAy/KeGa1gwYJaunSp+vXrpylTpqhSpUr6+OOP1a1bt6e6lkNW9mr9BrodFqYZ06fq1q2b8i9eQjNmfy0vuhmznB9/+F6S1KlD0uWFR342Rk3445Hp+OZ216IxHeXp5qhbt6O0/cA5VW83QbduR6nq80X1QumCkqRjvw5Pcj//BkMVHBJmhYqR3ng/NxbOd+qYzA/7dP8vU6dOlST16dNHn376qZydnS3bEhIStHnzZl24cEH792e+5Zpq166tkiVLWp6j0YwaNUqzZs3SpUuXUn0fowwTAozIo+L71i4BGej27unWLgFAOnFIxdf+qe4ZmDRpkqQHPQOzZs1KssKNnZ2d/Pz8nmq4jjXcvn1bQUFBCgoKSrOVkDKDGTNmqGLFivLy8tK2bdv0xRdf6P33+eMPAABgNKkOA+fPn5f0YNnPZcuWJbkicGZVrlw53b59W2PHjpW/v7+1y8kwp0+f1meffaawsDDlz59f/fr106BBg6xdFgAAADJYqocJAf/EMCEg62KYkLEwTAjIulIzTOixr0DcokULjR07Nln7uHHj1LJly8c9HAAAAAAreewwsHnzZjVo0CBZe/369bV58+Y0KQoAAABA+nvsMBAVFZXiEqLZs2dXZGRkmhQFAAAAIP09dhgIDAzUDz/8kKx9yZIlCggISJOiAAAAAKS/x77o2JAhQ9S8eXOdPXtWtWrVkiStX79e3333nZYuXZrmBQIAAABIH48dBl577TUtX75co0eP1tKlS5UjRw6VKVNGGzZskKenZ3rUCAAAACAdPPXSopGRkfr+++81d+5c7d27VwkJCWlVG55hLC0KZF0sLWosLC0KZF3psrToXzZv3qz27dsrb968mjBhgmrVqqUdO3Y86eEAAAAAZLDHGiZ07do1LViwQHPnzlVkZKRatWql2NhYLV++nMnDAAAAQCaT6p6B1157Tf7+/jp06JAmT56sq1evatq0aelZGwAAAIB0lOqegd9//109e/ZUt27dVLRo0fSsCQAAAEAGSHXPwNatW3Xnzh09//zzevHFFzV9+nTdunUrPWsDAAAAkI5SHQZeeuklffXVVwoJCVHXrl21ZMkS5c2bV4mJifrjjz90586d9KwTAAAAQBp7qqVFT548qblz52rx4sUKDw/XK6+8ohUrVqRlfXhGsbQokHWxtKixsLQokHWl69KikuTv769x48bp8uXL+v7775/mUAAAAAAy2FNfdAzGRM8AkHXRM2As9AwAWVe69wwAAAAAyLwIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMijAAAAAAGBRhAAAAADAowgAAAABgUIQBAAAAwKAIAwAAAIBBEQYAAAAAgyIMAAAAAAZFGAAAAAAMKpu1C0DmZDZbuwJkpOj78dYuARnIrviL1i4BGSgmLsHaJSADJSZauwJkJIdstv+5Dz0DAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhIF0YjKZtHz5cmuXAQAAADxUNmsXkFldu3ZNo0aN0sqVK3XlyhXlypVLZcuWVe/evVW7dm1rl4c08uOS7/TTD9/r6tUrkqTCRYqqy3vdVaVqdStXhrSwaN5XCtrwh4IvnJedvYMCy5RV9559VcCvoGWfy5eCNX3yeB3av0/34+7rpZerqO+Hg+XpldOKleNx9WlcUsPfKK8Zvx/XoEV7km1fOrCWXinrq7YTgrRyz6Vk2z2c7bTt80by9XJS/k5LFBEdlxFl4yksmDtHQevX6eKFc7L//9f3+737JXl9/7L0R639faVOnDim6Lt3tW7zDrm4ulqxajyphfPmaNOGpOe7e8+/z3fI1Stq3uiVFO/72diJqv3KqxlZ7jOFnoEncOHCBT3//PPasGGDvvjiCx0+fFirV69WzZo11aNHD2uXhzSU28dHPfv013c/LtN3P/ysii+8pN4f9NCZM6etXRrSwP69u9Wi1Ruas/B7TZn5leLj49W7e2fduxctSbp3L1q9e3SRSSZNmz1Ps+d9o7i4OA3o3UOJiYlWrh6pVb6QlzrWLqbDF8NS3N69fgmZzY8+xvQuL+tocHjaF4d0s3/vHr3e+g3NXfS9ps76WvHx8erZ7V3L61uSYmJi9FLlKurQqYsVK0Va2L93j1q0ekNfLfxeU2Z+/f/v53+f71y5ffTb2k1Jbu++974cHR1VqXJVK1dvXYSBJ9C9e3eZTCbt2rVLLVq0ULFixVSyZEn17dtXO3bsSPE+ly5dUqtWreTu7i5PT081adJEFy5csGzfvXu3XnnlFeXMmVNubm6qXr269u3bl+QYJpNJX3/9tZo1ayZHR0cVLVpUK1assGxfsGCB3N3dk9xn+fLlMplMlp+HDx+usmXLavbs2cqXL58cHR3VqlUrRUREPP0vJguqXqOWqlarrgIF/FTAr6A+6NVHjo6OOnzwgLVLQxqY9OUcNWzcTIUKF1HRYsX1yYhRun4tRCeOHZMkHTqwX9euXtEnI0apcNFiKly0mIaMGK0Tx45q7+6dVq4eqeFkn01fvV9FPb/6U+F37yfbHljAQ+83LKEes7c/9Bid6hSTm1N2TVt5LD1LRRqbMmOOGjVppkJFiqqYf3ENHTla10L+fn1L0htvtVP7dzqrVGAZK1aKtDDZ8n5e9P/fz0fr2j/ez21tbeWV0zvJbdPGdar1yqtydHSycvXWRRh4TGFhYVq9erV69OghJ6fk//P8+8O4JMXFxalevXpycXHRli1btG3bNjk7O+vVV1/V/fsP/jjduXNH7du319atW7Vjxw4VLVpUDRo00J07d5Ica8SIEWrVqpUOHTqkBg0a6M0331RYWMrfdj3MmTNn9OOPP+rXX3/V6tWrtX//fnXv3v2xjmFECQkJWr1qpe7di1bpsuWsXQ7Swd3/f725urlJkuLu35fJZFJ2OzvLPnb29rKxsdHB/ftSPAaeLePfeUFr9l9R0JFrybblsLPV1+9XUf/5u3QjIibF+/v7uunD5oF6b8Y2JSb+R/cBnmlRUUlf38jaou48+nyfOHZUp0+e0GtNW2RkWc8k5gw8pjNnzshsNqt48eKpvs8PP/ygxMREff3115Zv6efPny93d3cFBQWpbt26qlWrVpL7zJkzR+7u7tq0aZMaNWpkae/QoYPeeOMNSdLo0aM1depU7dq1S6++mvqxbjExMVq0aJF8fX0lSdOmTVPDhg01YcIE+fj4JNs/NjZWsbGxSdoSbexlb2+f6sfMzE6fOql2b7bR/fuxyuHoqIlTvlThwkWsXRbSWGJioiaPH6vSZcupcJGikqSSpcvIIUcOzZgyQe+931tmmTVz6iQlJCQo9NZNK1eM/9Kikp/K+Hmq5ierUtw+5u0K2nXqplbtvZzidrtsNpr7QRUN+W6fLodGyy+XS3qWi3SUmJioSV98rtJly1te38i6HryfP/p8//q/n+VXsJBKl+HLPXoGHpP5vwaWpuDgwYM6c+aMXFxc5OzsLGdnZ3l6eiomJkZnz56VJF2/fl2dO3dW0aJF5ebmJldXV0VFRSk4ODjJsUqXLm35t5OTk1xdXXXjxo3Hqid//vyWICBJlSpVUmJiok6ePJni/mPGjJGbm1uS2xdjxzzWY2ZmfgUL6oefl2vxdz+qVas3NPTjgTp79oy1y0Iam/D5Zzp39rRGjhlvafPw8NRnYydq65ZNql2loupWe0l37tyRf/EA2djw9vks8/V01OftK6jzl1sVG5d8fkf9559TtZI++iiFycR/GdamnE5didSPW8+nZ6nIAF+M+VTnzpzWZ2PH//fOyPTGf/6pzp09rU/HpHy+Y2JitPb3lfQK/D96Bh5T0aJFZTKZdOLEiVTfJyoqSs8//7y+/fbbZNu8vb0lSe3bt1doaKimTJmiAgUKyN7eXpUqVbIMI/pL9uzZk/xsMpksExltbGyShZW4uKdf8WLQoEHq27dvkrZEG2P0CkhS9ux2yp+/gCQpoGQpHT16WN99s0hDho20cmVIKxM+/0zbtmzSjK8XKlfupL1jL1aqrKUrViv89m3ZZrOVi4urGr1STXl961upWqRG2UJeyuWWQ5tHN7S0ZbO1UeXiudWlrr/mrjulgrldFDy3dZL7Le5TTdtP3FCjT/9QtZI+KpnfXU1efFOS9Nf0q3NzWmn88sMas/RQhj0fPLkvxnymrZs3afa8RcqdO3nvN7KW8f//fj7z60XJ3s//snHdWsXE3FP9Rk0yuLpnE2HgMXl6eqpevXr68ssv1bNnz2TzBsLDw5PNGyhfvrx++OEH5cqVS64PWbJs27ZtmjFjhho0aCDpwYTjW7duPVZt3t7eunPnju7evWup68CBA8n2Cw4O1tWrV5U3b15J0o4dO2RjYyN/f/8Uj2tvn3xI0D0Dr6qXmJiYLKQhczKbzZo4dpQ2bVyvL79aoLy+zz10X3cPD0nSnl07dDssTFWq18yoMvEENh0J0UsDfk3SNuO9Sjp1NVKTVxxV6J0YzV+XdFWwHV+8pkGL9mr1vgfDhtpN2iQHu7//TJYv7KUZ772sV0es0fnrUen/JPBUzGazxn8+Sps2rNOMrx/9+kbmZzabNWHsKG3auE4z/uP9/Nf//ayq1WvJw8MzAyt8dhEGnsCXX36pypUr64UXXtDIkSNVunRpxcfH648//tDMmTN1/PjxJPu/+eab+uKLL9SkSRONHDlSzz33nC5evKhly5bpww8/1HPPPaeiRYtq8eLFqlChgiIjIzVgwADlyJHjsep68cUX5ejoqMGDB6tnz57auXOnFixYkGw/BwcHtW/fXuPHj1dkZKR69uypVq1apThfwOimTpqgylWrySdPHkXfvavfV/6mPbt3acbsudYuDWlg/Oef6o/fV2nspGlydHS0zANwdnaRvYODJOm3//0iv4KF5O7hoSOHDmry+DFq/Wa7JGuV49kTFROv45fDk7TdjY1XWFSspT2lScOXQ+/q4s0HH/TP30j6gd/L5cGXIqeuRHCdgUzgi9Gfas3vK/XF5OlycnKyvL6dnF3k8P+v79BbNxV665YuX3owJPfMmVNycnRS7jx55Obmbq3S8QTGf/6p1v6+UmMnTZejY8rnW5IuBV/UgX17NGHqLGuV+swhDDyBQoUKad++fRo1apT69eunkJAQeXt76/nnn9fMmTOT7e/o6KjNmzdr4MCBat68ue7cuSNfX1/Vrl3b0lMwd+5cdenSReXLl1e+fPk0evRo9e/f/7Hq8vT01DfffKMBAwboq6++Uu3atTV8+HB16ZJ0/eQiRYqoefPmatCggcLCwtSoUSPNmDHjyX8hWVhYWKg+GTxQt27ekLOLi4oV89eM2XNV6eXK1i4NaeCXn36QJPXo3CFJ+8fDP1PDxs0kScEXz2vW9EmKjIhQnry+at+pi9q82T6jSwXwmH7+aYkkqdu7SV+vQ0aMUqMmD17fy376QV/P/vvv33vvtEu2DzKHZf9/vnt0Tnq+Pxk+yvJ+Lkm//W+ZcuXOrRcr8Xf8Lybzk8yIRaY1fPhwLV++PMXhQ4/DyMOEjCj6fry1S0AGKvTu99YuARno4ry21i4BGYjrJRqLp5Ptf+7DchgAAACAQREGAAAAAINimBCeCMOEjIVhQsbCMCFjYZiQsTBMyFgYJgQAAADgoQgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABpXN2gUgc7oWEWPtEpCBIqLjrF0CMlC/dypZuwRkILtsfC9oJP1WHLd2CchAM1sE/Oc+vAMAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEERBgAAAACDIgwAAAAABkUYAAAAAAyKMAAAAAAYFGEAAAAAMCjCAAAAAGBQhAEAAADAoAgDAAAAgEEZNgx06NBBTZs2faL7LliwQO7u7qne38/PT5MnT36ix/qnoKAgmUwmhYeHP/WxAAAAgGzWfPCbN29q6NChWrlypa5fvy4PDw+VKVNGQ4cOVeXKla1Z2iO1bt1aDRo0SNfHqFGjhsqWLZskRLz88ssKCQmRm5tbuj620d26eV1zZ0zWnh3bFBsTo7zP5VPfwSNVrERJyz7BF85p7ozJOnxgrxIS4pXfr7CGjJqgXD55rFg5/suxQ/v060+Ldf7Ucd0Ou6X+w8erYuUalu1ms1k/LZyt9b//ortRUfIvWUbv9vxIeZ7Lb9nn6uWL+nbOFJ08elDx8fHKX7CIWnXoplJlK1jhGeFRjqz5UZcOblfk9cuyzW4n70IlVK5JR7nmfs6yz87vp+nayQO6FxGmbPYO8i5YQmWbdJSbTz7LPt++3zDZsSt3+FB+FapnyPNA2pj15TTNnvllkja/ggX1y6+/W6kiPKl6/l4qm9dVPi52iksw62xYtJYfvqHrUfeT7FfQM4ealMwlP88cSjSbdTk8RtO2Bisu0SxJyuVsp+aBuVXYK4dsbUy6EhGrX4/d0Kmb0dZ4WlZj1TDQokUL3b9/XwsXLlShQoV0/fp1rV+/XqGhodYs6z/lyJFDOXLkyPDHtbOzk4+PT4Y/rpHciYxU3/c6qEz5Cvpswpdyc/fQlUvBcnZxtexz9fIl9evWQfUaNdPb73aTo6OzLp4/Kzt7OytWjtSIjbmnAoWKqma9xpowYkCy7St+WKjfly9R9w+HK5ePr35cMFOjB32gCXN/lJ2dvSRp3Cd95OObT0O+mCU7O3utWva9xg3prakLl8vdM2dGPyU8wo0zh1WsWkN5FSgmc0KCDvy6UOunf6LXPpmlbPYOkiTPfEXkV7GmnDy8dT/6jg6t/FYbvhyiJiPmysbG1nKsl97qrbwBz1t+tsvhnOHPB0+vcJGimvX1PMvPtrZW/RiEJ1Q0p5M2nQvTxbAY2dhITUrm0gdV8mvkH2d1P+HBB/2Cnjn0QZX8Wn3iln44cE2JZrN83Rxk/sdxur+cTzei7mvy5ou6n2hW7SKe6v5yfg1dfVqRsQnWeXJWYLVhQuHh4dqyZYvGjh2rmjVrqkCBAnrhhRc0aNAgNW7c2LLfxIkTFRgYKCcnJ+XLl0/du3dXVFSUZftfQ3bWrFmjEiVKyNnZWa+++qpCQkIs+yQkJKhv375yd3eXl5eXPvzwQ5nNf//v8Ntvv8nd3V0JCQ9O/IEDB2QymfTRRx9Z9nn33Xf11ltvJXnMf/r1119VsWJFOTg4KGfOnGrWrFmS7dHR0XrnnXfk4uKi/Pnza86cOQ/93XTo0EGbNm3SlClTZDKZZDKZdOHChWTDhP6q47fffpO/v78cHR31+uuvKzo6WgsXLpSfn588PDzUs2dPy3OTpNjYWPXv31++vr5ycnLSiy++qKCgoP84Y8bw07fz5J0rt/p9/Kn8AwLlk/c5Pf/iy8r73N/fEi6cM00VK1XRuz36qEixEsr7XD5VqlpD7h5eVqwcqVHuhcpq07G7XqhSM9k2s9msVb98r+ZvdlLFl2uoQKGi6jFwpG6H3tTubUGSpMiIcIVcCVaTNh1UoFBR5Xkuv9q++75iY2IUfOFsBj8b/JdaPT5V4ZdekXueAvJ4rpAqvdVX0bdvKvTSGcs+RavUV+4ipeTslVue+YqozGvtFH37pu6G3khyLLsczsrh6mm52WYn/GdGtra2ypnT23Lz8PCwdkl4AtO3BWvHxQiF3InVlYhYLdpzVV5Odsrv8fcXtS1L59bGM2FaeypUIXdidT3qvvZdiVT8//cKONnZKreLvdaeDNWVyFjdjLqvX47ckH02G+V1c7DWU7MKq4UBZ2dnOTs7a/ny5YqNjX3ofjY2Npo6daqOHj2qhQsXasOGDfrwww+T7BMdHa3x48dr8eLF2rx5s4KDg9W/f3/L9gkTJmjBggWaN2+etm7dqrCwMP3yyy+W7VWrVtWdO3e0f/9+SdKmTZuUM2fOJB+QN23apBo1aqRY48qVK9WsWTM1aNBA+/fv1/r16/XCCy8k2WfChAmqUKGC9u/fr+7du6tbt246efJkisebMmWKKlWqpM6dOyskJEQhISHKly9fivtGR0dr6tSpWrJkiVavXq2goCA1a9ZMq1at0qpVq7R48WLNnj1bS5cutdzn/fff159//qklS5bo0KFDatmypV599VWdPn06xccwkh1bN6lY8ZL67JP+at2whnp0aKXfV/xs2Z6YmKhd27fIN18BDe7znlo3rKFend/U9s0brFg10sKNa1cUHhaqwHJ/v3YdnZxVpHgpnT52WJLk4uqmvPkKaPMfKxVz754SEuK1buUyubl7qlDREtYqHakUF3NXkmTvmPK3+vGxMTq34w85e+WWo0fSXp7dP87U0oFvaPUXfXT2z7VJvlBC5hEcfFGv1KyqRq/W0eCB/RUSctXaJSEN5Mj+4ONs9P0HX3y62NuqoJej7sTGq38NP41tWEx9qhVQYa+/w8Ld+wm6didWLxZwk52tSTYmqWpBD0XGxCv49j2rPA9rsVr/WLZs2bRgwQJ17txZs2bNUvny5VW9enW1adNGpUuXtuzXu3dvy7/9/Pz02Wef6b333tOMGTMs7XFxcZo1a5YKFy4s6cGH3ZEjR1q2T548WYMGDVLz5s0lSbNmzdKaNWss293c3FS2bFkFBQWpQoUKCgoKUp8+fTRixAhFRUUpIiJCZ86cUfXqKY8PHTVqlNq0aaMRI0ZY2sqUKZNknwYNGqh79+6SpIEDB2rSpEnauHGj/P39kx3Pzc1NdnZ2cnR0/M9hQXFxcZo5c6blub/++utavHixrl+/LmdnZwUEBKhmzZrauHGjWrdureDgYM2fP1/BwcHKmzevJKl///5avXq15s+fr9GjRyd7jNjY2GSBLTbWLHt7+0fWlhmFXL2s35b/qOat31abdp106vhRzZw0VtmyZdcrDRor/HaY7t2L1o/fzFP7zu+rU7fe2rNzmz4d3Fdjp32t0uUYN55ZhYc9GJ7o9q8eHjcPT4XffrDNZDLpk7EzNH5Yf3VoUk0mk43c3D00aMzUJEPJ8OwxJyZqz9I58i4UIPe8fkm2ndr8m/Yvn6/4+zFyzf2car0/SrbZslu2l274lnIXK6NsdvYKObFPu36YobjYGBWv0VjIPEqVLqORn41RAb+CunXrhmbP+FLvtHtLS5evkJMTw74yK5OklmV8dOZWtK5GPvisktPpQc9dwxLeWnb4ui6Fx+qlAm7qVbWAPl13Tjf/f27BlC0X9V6lfJrUpLjMZulObLymbQ1WdFyitZ6OVVh1NaEWLVro6tWrWrFihV599VUFBQWpfPnyWrBggWWfdevWqXbt2vL19ZWLi4vefvtthYaGKjr678kdjo6Olg/DkpQnTx7duPGgizciIkIhISF68cUXLduzZcumChWSfmirXr26goKCZDabtWXLFjVv3lwlSpTQ1q1btWnTJuXNm1dFixZN8XkcOHBAtWvXfuRz/WfAMZlM8vHxsdT4NP793HPnzi0/Pz85OzsnafvrsQ4fPqyEhAQVK1bM0jvj7OysTZs26ezZlIc5jBkzRm5ubkluM6d88dS1P4vMiYkqUqyEOr7XU0WKlVCDJq/r1cbNtXL5T5btklSpak01b/O2ChcrrtZvd9ILL1ez7IOsy2w2a960sXJ199DwiV9p1PSFqlC5hsYN6avbobesXR4eYfePMxURclFVOg5Mts2vYk3V/2iq6vQeKxfvvNo6b4wS4v6eiBhY/w3lKhwgz3yFVfKVlgqo00LH1/2c7Dh4tlWpWk2v1HtVxfz99XLlqpo+c46i7kRq7erV1i4NT6FNOR/ldbXX3F2XLW2m///v1vPh+vNihC5HxGjpoeu6HnVfLxdw//u+ZfPoTmy8Jmy6oLEbz+vg1Tvq/nI+uToYay6J1ZcWdXBw0CuvvKIhQ4Zo+/bt6tChg4YNGyZJunDhgho1aqTSpUvr559/1t69e/Xllw9WArh//+836uzZsyc5pslkeuwu3Bo1amjr1q06ePCgsmfPruLFi6tGjRoKCgrSpk2bHtorIClVk4lTqjEx8emTZ0rHfdRjRUVFydbWVnv37tWBAwcst+PHj2vKlCkpPsagQYMUERGR5NatV/LJl1mBp5e38vsVStKW36+Qbl5/MAfF1d1DtrbZUtinoG5ev5ZhdSLtuXs+6BGIuJ10AYOI22GW+SBH9u/W3p1b1evj0SpeqqwKFS2ud3t+JDs7e23647cMrxmps/vHmbpyZJfq9ByTbPiPJNnlcJJrLl/lLlJKVd8drIjrl3Xp4PaHHi+nn7+iw28pIS4uPctGOnNxdVX+An66FHzR2qXgCbUu66NSPi6atPmiwu/FW9ojYh78OyQy6aiGa5Gx8nR88BnJ39tJgXmcNXfnFZ0LvadL4TFacuCa4hIT9VJ+Y63aaPUw8G8BAQG6e/fBuM69e/cqMTFREyZM0EsvvaRixYrp6tXHG9/n5uamPHnyaOfOnZa2+Ph47d27N8l+f80bmDRpkuWD/19hICgo6KHzBaQH3/qvX7/+ser6L3Z2dkkm/aaVcuXKKSEhQTdu3FCRIkWS3B42JMne3l6urq5JbllxiJAkBZQuq8vBF5K0XQm+qFw+D4ZUZc+eXcVKlEy+z6WLLCuayeXy8ZW7p5cO799taYu+G6UzJ46oaECgJOl+bIykB3OZ/slkY7L0GuHZYTabtfvHmbp08E/V7jlazjlTsRqb+cEtIf7hH/RvXz4nO0dn2f7rixdkLtHRd3X50iXl9Pa2dil4Aq3L+qhsXhdN3nJRodFJX6+h0XEKvxen3C5JJ/rndrFT2P/va5ftQf/Bv788NpslG5NJRmK1fpDQ0FC1bNlS77zzjkqXLi0XFxft2bNH48aNU5MmTSRJRYoUUVxcnKZNm6bXXntN27Zt06xZsx77sXr16qXPP/9cRYsWVfHixTVx4sRkF+7y8PBQ6dKl9e2332r69OmSpGrVqqlVq1aKi4t7ZM/AsGHDVLt2bRUuXFht2rRRfHy8Vq1apYEDk3dHp5afn5927typCxcuyNnZWZ6enk98rH8qVqyY3nzzTbVr104TJkxQuXLldPPmTa1fv16lS5dWw4bJ19M2kmat31Lfru21ZOHXqla7rk4eO6JVK5aq14dDLfu83ra9xgz9UIFln1eZ8hW1Z8c27di2WeOmfW3FypEaMfeide3KJcvPN65d0YUzJ+Xs6qacuXzUoNkb+uW7ucrjm0+58vjqhwUz5eHlbbkWQdGA0nJ2dtGX44apxVudZWdvrw2rluvGtasq92IVKz0rPMzuH2fowp5Nqt5liLI75NC9yDBJUnYHJ2Wzs9edWyG6uHeL8pQoJwdnN0WH39LRtT/JNrudfEtWlCRdPrxTMXfCldPPX7bZ7RRyYr+OrP1RAbWbW/Op4QlM/GKsqtWoqbx58+rGjRua9eV02dja6NUGjaxdGh5Tm7I+qpjPTbP+vKTYuAS52j9YBvheXKLlGgJ/nApVowBvXY6I0eXwGL1UwF25Xew1Z8eD4UTnQu8p+n6C2lf01crjNxWXYFaVgu7ycrLT4Wt3rPbcrMFqYcDZ2VkvvviiJk2apLNnzyouLk758uVT586dNXjwYEkPJuFOnDhRY8eO1aBBg1StWjWNGTNG7dq1e6zH6tevn0JCQtS+fXvZ2NjonXfeUbNmzRQREZFkv+rVq+vAgQOWXgBPT08FBATo+vXrKU70/UuNGjX0008/6dNPP9Xnn38uV1dXVatW7fF+If/Sv39/tW/fXgEBAbp3757Onz//VMf7p/nz5+uzzz5Tv379dOXKFeXMmVMvvfSSGjXiDdG/RCkNHTNR82dN1bcLZssnj6/e6/WhatX7OyRVrl5bHwz4RD8snqeZk8bqufx+GjJqgkqVKW/FypEaZ08d08j+71l+XjRrkiSp+iuN1P3D4Wrcur1iY2I0Z/JoRUfdkX+psho0ZqrlGgOubu4aNHqalsyfoU8HdFNCQryeK1BIA0ZMkF/hYlZ5Tni401tWSZLWTfkoSftLb/VW4ZdekW02O908e1Qng/6n+9FRcnBxV64ipVSv33g5uLhLkmxsbXVq82/a+/NXktksF+88er55ZxV5uV5GPx08pevXr2vQh/0UER4uD09PlS33vBZ9+0OafdmGjFO98INz1re6X5L2hXuuaMfFB5/tNpwJUzYbk14v7SMnO1tdjojR1C0Xdevug56Bu/cTNG1rsJqUyqXeVQvI1sakkMhYzdp+SVciHr7KZVZkMrM+Gp7A+Vsx1i4BGSgimrHRRrLi5HVrl4AM1L9G4f/eCVlGvxXHrV0CMtDMFgH/uc8zN2cAAAAAQMYgDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgCAMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAAAAAwKMIAAAAAYFCEAQAAAMCgTGaz2WztIoDMIDY2VmPGjNGgQYNkb29v7XKQzjjfxsL5NhbOt7Fwvh+NMACkUmRkpNzc3BQRESFXV1drl4N0xvk2Fs63sXC+jYXz/WgMEwIAAAAMijAAAAAAGBRhAAAAADAowgCQSvb29ho2bBiTjwyC820snG9j4XwbC+f70ZhADAAAABgUPQMAAACAQREGAAAAAIMiDAAAAAAGRRgAAAAADIowAAAAABgUYQAA/uHMmTNas2aN7t27J0liwbWsKTIyMsXbnTt3dP/+fWuXB+ApnT17Vp988oneeOMN3bhxQ5L0+++/6+jRo1au7NlDGAAASaGhoapTp46KFSumBg0aKCQkRJLUqVMn9evXz8rVIa25u7vLw8Mj2c3d3V05cuRQgQIFNGzYMCUmJlq7VKShGzduaMuWLdqyZYvlAyKynk2bNikwMFA7d+7UsmXLFBUVJUk6ePCghg0bZuXqnj2EAQCQ1KdPH2XLlk3BwcFydHS0tLdu3VqrV6+2YmVIDwsWLFDevHk1ePBgLV++XMuXL9fgwYPl6+urmTNnqkuXLpo6dao+//xza5eKNHDnzh29/fbb8vX1VfXq1VW9enX5+vrqrbfeUkREhLXLQxr76KOP9Nlnn+mPP/6QnZ2dpb1WrVrasWOHFSt7NmWzdgHAs2zq1KkptptMJjk4OKhIkSKqVq2abG1tM7gypLW1a9dqzZo1eu6555K0Fy1aVBcvXrRSVUgvCxcu1IQJE9SqVStL22uvvabAwEDNnj1b69evV/78+TVq1CgNHjzYipUiLbz77rvav3+/fvvtN1WqVEmS9Oeff6pXr17q2rWrlixZYuUKkZYOHz6s7777Lll7rly5dOvWLStU9GwjDACPMGnSJN28eVPR0dHy8PCQJN2+fVuOjo5ydnbWjRs3VKhQIW3cuFH58uWzcrV4Gnfv3k3SI/CXsLAwLmGfBW3fvl2zZs1K1l6uXDn9+eefkqQqVaooODg4o0tDOvjtt9+0Zs0aValSxdJWr149ffXVV3r11VetWBnSg7u7u0JCQlSwYMEk7fv375evr6+Vqnp2MUwIeITRo0erYsWKOn36tEJDQxUaGqpTp07pxRdf1JQpUxQcHCwfHx/16dPH2qXiKVWtWlWLFi2y/GwymZSYmKhx48apZs2aVqwM6SFfvnyaO3dusva5c+dagn1oaKjlSwBkbl5eXnJzc0vW7ubmxjnOgtq0aaOBAwfq2rVrlvfybdu2qX///mrXrp21y3vmmMwslQE8VOHChfXzzz+rbNmySdr379+vFi1a6Ny5c9q+fbtatGhhmXCKzOnIkSOqXbu2ypcvrw0bNqhx48Y6evSowsLCtG3bNhUuXNjaJSINrVixQi1btlTx4sVVsWJFSdKePXt04sQJLV26VI0aNdLMmTN1+vRpTZw40crV4mnNmTNHP/30kxYvXiwfHx9J0rVr19S+fXs1b95cXbt2tXKFSEv3799Xjx49tGDBAiUkJChbtmxKSEhQ27ZttWDBAob2/gthAHgER0dHbd68WRUqVEjSvnv3blWvXl3R0dG6cOGCSpUqZVmtAJlXRESEpk+froMHDyoqKkrly5dXjx49lCdPHmuXhnRw/vx5zZ49W6dOnZIk+fv7q2vXrvLz87NuYUhz5cqV05kzZxQbG6v8+fNLkoKDg2Vvb6+iRYsm2Xffvn3WKBHpIDg4WEeOHFFUVJTKlSuX7FzjAcIA8AgNGzbUtWvX9PXXX6tcuXKSHvQKdO7cWT4+Pvrtt9/066+/avDgwTp8+LCVqwUApGTEiBGp3pelJ2E0hAHgEa5du6a3335b69evV/bs2SVJ8fHxql27thYvXqzcuXNr48aNiouLU926da1cLZ5WTEyMDh06pBs3biRbX75x48ZWqgrpJTw8XLt27UrxfDOuGMi8zGazli5dqo0bN6b4+l62bJmVKns2EQaAVDhx4kSSoQT+/v5WrghpbfXq1WrXrl2Ky86ZTCYlJCRYoSqkl19//VVvvvmmoqKi5OrqKpPJZNlmMpkUFhZmxeoAPI1evXpp9uzZqlmzpnLnzp3k9S1J8+fPt1JlzybCAADowfUE6tatq6FDhyp37tzWLgfp7K8rTY8ePTrFJWWRtdjY2CT7QPhPhP2sxdPTU998840aNGhg7VIyBa4zADxCQkKCFixYoPXr16fY1bhhwwYrVYa0dv36dfXt25cgYBBXrlxRz549CQIG8csvvyT5OS4uTvv379fChQsfaz4BMgc3NzcVKlTI2mVkGoQB4BF69eqlBQsWqGHDhipVqtQjv1lC5vb6668rKCiIJUQNol69etqzZw8fGAyiSZMmydpef/11lSxZUj/88IM6depkhaqQXoYPH64RI0Zo3rx5ypEjh7XLeeYxTAh4hJw5c2rRokV0NRpAdHS0WrZsKW9vbwUGBlomjP+lZ8+eVqoM6WHu3LkaOXKkOnbsmOL5ZsK4MZw7d06lS5dmaegs5t69e2rWrJm2bdsmPz+/ZK9vlo9Nip4B4BHs7OxUpEgRa5eBDPD9999r7dq1cnBwUFBQULIJpYSBrKVz586SpJEjRybbxoRxY7h3756mTp0qX19fa5eCNNa+fXvt3btXb731VooTiJEUPQPAI0yYMEHnzp3T9OnTeTPJ4nx8fNSzZ0999NFHsrGxsXY5ANKQh4dHkvdws9msO3fuyNHRUd988w09QVmMk5OT1qxZoypVqli7lEyBngHgEbZu3aqNGzfq999/V8mSJZN1NbJWcdZx//59tW7dmiAAZEGTJ09O8rONjY28vb314osvysPDwzpFId3ky5dPrq6u1i4j06BnAHiEjh07PnI7axVnHX369JG3t7cGDx5s7VKQTqZOnaouXbrIwcFBU6dOfeS+DAsDMq+VK1dq2rRpmjVrlvz8/KxdzjOPMAAAevDhb9GiRSpTpoxKly6drBdo4sSJVqoMaaVgwYLas2ePvLy8VLBgwYfuZzKZdO7cuQysDBmBK04bh4eHh6KjoxUfHy9HR8dk7+dcVDApwgAASKpZs+ZDt5lMJq4pAWRiXHHaWBYuXPjI7e3bt8+gSjIHwgDwL+XLl9f69evl4eGhcuXKPXLiMMuTAcCzjytOAw/HBGLgX5o0aSJ7e3tJUtOmTa1bDIB0wdXFjYUrTmd9kZGRlknDkZGRj9yXycVJ0TMAwLCaN2+uBQsWyNXVVc2bN3/kvqwclbW8//77lquL58mTJ1kP4KRJk6xUGdJD8+bN1aZNG7Vq1crapSCd2NraKiQkRLly5ZKNjU2Kvfpms5nriKSAngHgETZu3PjQseSzZ89W165dM7gipCU3NzfLH4x/jyNG1rZkyRL9+OOPXF3cIBo2bKgBAwbo2LFjXHE6i9qwYYM8PT0lPfjbjdSjZwB4BHt7e/Xs2VOjR4+2/PG4deuWOnbsqK1bt+r27dtWrhDAk8ibN6+CgoJUrFgxa5eCDPCo64fwTXHWExwcrHz58iX7gsdsNuvSpUvKnz+/lSp7NnF1HeARNm7cqF9++UUVK1bUsWPHtHLlSpUqVUqRkZE6cOCAtctDGqpVq5bCw8OTtUdGRqpWrVoZXxDSVb9+/TRlyhTxfZgxJCYmPvRGEMh6ChYsqJs3byZrDwsLe+SywkZFzwDwH6KiovTee+9p6dKlSkxM1KeffqoPP/yQISVZjI2Nja5du6ZcuXIlab9x44Z8fX0VFxdnpcqQHpo1a6aNGzfK09OTq4sDWYyNjY2uX78ub2/vJO0XL15UQECA7t69a6XKnk3MGQD+w6lTp7Rnzx4999xzunr1qk6ePKno6Gg5OTlZuzSkgUOHDln+fezYMV27ds3yc0JCglavXi1fX19rlIZ05O7urmbNmlm7DGSgu3fvatOmTQoODtb9+/eTbOOK01lD3759JT0Y+jVkyJAkq0clJCRo586dKlu2rJWqe3YRBoBH+PzzzzVs2DB16dJFX3zxhc6cOaO3335bpUuX1jfffKNKlSpZu0Q8pbJly8pkMslkMqU4HChHjhyaNm2aFSpDeomPj1fNmjVVt25d+fj4WLscZID9+/erQYMGio6O1t27d+Xp6albt27J0dFRuXLlIgxkEfv375f0YG7A4cOHZWdnZ9lmZ2enMmXKqH///tYq75nFMCHgEfLkyaN58+apfv36lra4uDgNHjxYU6dOVWxsrBWrQ1q4ePGizGazChUqpF27diXpVrazs1OuXLlka2trxQqRHhwdHXX8+HEVKFDA2qUgA9SoUUPFihXTrFmz5ObmpoMHDyp79ux666231KtXr/9cWhiZS8eOHTVlyhSuJ5BKhAHgEW7duqWcOXOmuG3Tpk2qXr16BlcEIC3UqFFDvXv35sKCBuHu7q6dO3fK399f7u7u+vPPP1WiRAnt3LlT7du314kTJ6xdImA1DBMCHuFhQUASQQDIxLp3765+/frp8uXLev7555PNASpdurSVKkN6yJ49u2V50Vy5cik4OFglSpSQm5ubLl26ZOXqAOuiZwD4D3v27NGPP/6Y4qQzVhwBMqeU1p03mUxcoTSLqlu3rjp06KC2bduqc+fOOnTokHr27KnFixfr9u3b2rlzp7VLBKyGngHgEZYsWaJ27dqpXr16Wrt2rerWratTp07p+vXrrEQCZGLnz5+3dgnIQKNHj9adO3ckSaNGjVK7du3UrVs3FS1aVPPmzbNydYB10TMAPELp0qXVtWtX9ejRQy4uLjp48KAKFiyorl27Kk+ePBoxYoS1SwQAAHhihAHgEZycnHT06FH5+fnJy8tLQUFBCgwM1PHjx1WrVi2FhIRYu0SkofDwcC1dulRnz57VgAED5OnpqX379il37txcayALOnv2rCZPnqzjx49LkgICAtSrVy8VLlzYypUhPcTHxysoKEhnz55V27Zt5eLioqtXr8rV1VXOzs7WLg9p7PTp09q4caNu3LihxMTEJNuGDh1qpaqeTQwTAh7Bw8PD0rXs6+urI0eOKDAwUOHh4YqOjrZydUhLhw4dUp06deTm5qYLFy6oc+fO8vT01LJlyxQcHKxFixZZu0SkoTVr1qhx48YqW7asKleuLEnatm2bSpYsqV9//VWvvPKKlStEWrp48aJeffVVBQcHKzY2Vq+88opcXFw0duxYxcbGatasWdYuEWnoq6++Urdu3ZQzZ075+PjIZDJZtplMJsLAv9AzADxC27ZtVaFCBfXt21effvqppk2bpiZNmuiPP/5Q+fLlmUCchdSpU0fly5fXuHHjLEPCChUqpO3bt6tt27a6cOGCtUtEGipXrpzq1aunzz//PEn7Rx99pLVr12rfvn1WqgzpoWnTpnJxcdHcuXPl5eVleX0HBQWpc+fOOn36tLVLRBoqUKCAunfvroEDB1q7lEyBMAA8QlhYmGJiYpQ3b14lJiZq3Lhx2r59u4oWLapPPvlEHh4e1i4RacTNzU379u1T4cKFk4SBixcvyt/fXzExMdYuEWnIwcFBhw8fVtGiRZO0nzp1SqVLl+Z8ZzFeXl7avn27/P39k7y+L1y4oICAAHp6sxhXV1cdOHBAhQoVsnYpmQLDhIBH8PT0tPzbxsZGH330kRWrQXqyt7dXZGRksvZTp04luSoxsgZvb28dOHAgWRg4cOCAcuXKZaWqkF4SExNTXC728uXLcnFxsUJFSE8tW7bU2rVr9d5771m7lEyBMAD8S0ofCB+GS51nHY0bN9bIkSP1448/SnowrjQ4OFgDBw5UixYtrFwd0lrnzp3VpUsXnTt3Ti+//LKkB3MGxo4dq759+1q5OqS1unXravLkyZozZ46kB6/vqKgoDRs2TA0aNLBydUgLU6dOtfy7SJEiGjJkiHbs2KHAwEBlz549yb49e/bM6PKeaQwTAv7FxsYmyWSjlHBhoqwnIiJCr7/+uvbs2aM7d+4ob968unbtmipVqqRVq1Ylu0ItMjez2azJkydrwoQJunr1qiQpb968GjBggHr27Pmf7wHIXC5fvqx69erJbDbr9OnTqlChgk6fPq2cOXNq8+bN9AZlAQULFkzVfiaTSefOnUvnajIXwgDwL5s2bUr1vtWrV0/HSmANW7du1aFDhxQVFaXy5curTp061i4J6eyvFcMYLpK1xcfHa8mSJUle32+++aZy5Mhh7dIAqyIMAMC/xMTEyN7enm+HAQBZHnMGgP+wZcsWzZ49W+fOndNPP/0kX19fLV68WAULFlSVKlWsXR7SSGJiokaNGqVZs2bp+vXrOnXqlAoVKqQhQ4bIz89PnTp1snaJSEOhoaEaOnToQy9KFBYWZqXKkFZWrFiR6n0bN26cjpUgo7Vo0UIvvPBCsqVFx40bp927d+unn36yUmXPJsIA8Ag///yz3n77bb355pvat2+fYmNjJT0YXz569GitWrXKyhUirXz22WdauHChxo0bp86dO1vaS5UqpcmTJxMGspi3335bZ86cUadOnZQ7d256gbKgpk2bpmo/5n9lPZs3b9bw4cOTtdevX18TJkzI+IKecQwTAh6hXLly6tOnj9q1a5dkber9+/erfv36unbtmrVLRBopUqSIZs+erdq1ayc51ydOnFClSpV0+/Zta5eINOTi4qKtW7eqTJky1i4FQBrLkSOHDhw4IH9//yTtJ06cULly5XTv3j0rVfZssrF2AcCz7OTJk6pWrVqydjc3N4WHh2d8QUg3V65cUZEiRZK1JyYmKi4uzgoVIT0VL16cDwQGsGHDBgUEBKS4ZHRERIRKliypLVu2WKEypKfAwED98MMPydqXLFmigIAAK1T0bGOYEPAIPj4+OnPmjPz8/JK0b926lSsbZjEBAQHasmWLChQokKR96dKlKleunJWqQnqZMWOGPvroIw0dOlSlSpVKtg451xDJGiZPnqzOnTuneD7d3NzUtWtXTZw4UVWrVrVCdUgvQ4YMUfPmzXX27FnVqlVLkrR+/Xp9//33zBdIAWEAeITOnTurV69emjdvnkwmk65evao///xT/fr109ChQ61dHtLQ0KFD1b59e125ckWJiYlatmyZTp48qUWLFum3336zdnlIY+7u7oqMjLR8UPgL1xDJWg4ePKixY8c+dHvdunU1fvz4DKwIGeG1117T8uXLNXr0aC1dulQ5cuRQ6dKltW7dOpYETwFzBoBHMJvNGj16tMaMGaPo6GhJkr29vQYMGKBBgwaxPnUWs2XLFo0cOVIHDx60rEM+dOhQ1a1b19qlIY298MILypYtm3r16pXiBGI+MGQNDg4OOnLkSIpDACXpzJkzCgwMZMgYDI2eAeARTCaTPv74Yw0YMEBnzpxRVFSUAgICNHv2bBUsWJAJxJnc1KlT1aVLFzk4OCg4OFhVqlTRH3/8Ye2ykAGOHDmi/fv3J5tgiKzF19f3kWHg0KFDypMnTwZXBTxbmEAMpCA2NlaDBg1ShQoVVLlyZa1atUoBAQE6evSo/P39NWXKFPXp08faZeIp9e3b1zKxsGDBgrp586aVK0JGqVChgi5dumTtMpDOGjRooCFDhigmJibZtnv37mnYsGFq1KiRFSpDWvP09NStW7ckSR4eHvL09HzoDUkxTAhIwcCBAzV79mzVqVNH27dv182bN9WxY0ft2LFDgwcPVsuWLWVra2vtMvGU8ufPr0GDBqlBgwYqWLCg9uzZo5w5cz50X2QdP/30k4YPH64BAwYoMDAw2QTi0qVLW6kypKXr16+rfPnysrW11fvvv2/pCTpx4oS+/PJLJSQkaN++fcqdO7eVK8XTWrhwodq0aSN7e3stWLDgkdcOad++fQZW9uwjDAApKFSokCZPnqzGjRvryJEjKl26tDp06KC5c+dycaIsZM6cOfrggw8UHx//0H2YUJo12dgk7xg3mUyc7yzo4sWL6tatm9asWaO/PvKYTCbVq1dPX375pQoWLGjlCgHrIgwAKbCzs9P58+fl6+sr6cEFTHbt2qXAwEArV4a0dufOHV28eNGy0oSXl1eK+3Fxqqzl4sWLj9z+7yVmkfndvn1bZ86ckdlsVtGiReXh4WHtkpBO2rVrp5o1a6patWoqXLiwtct55hEGgBTY2trq2rVr8vb2lvTgaqWHDh3iG6Qs5p8TiBcuXKhWrVqxQhQAZHLvvvuuNm/erDNnzsjX11fVq1dXjRo1VL16dRUtWtTa5T1zCANACmxsbFS/fn3Z29tLkn799VfVqlVLTk5OSfZbtmyZNcpDGsmWLZuuXr2qXLlyydbWViEhIcqVK5e1ywIApIErV65o8+bN2rRpkzZt2qRTp04pT548unz5srVLe6awtCiQgn9PLnrrrbesVAnSU968efXzzz+rQYMGMpvNunz5coqrjkhMIAaAzMbDw0NeXl7y8PCQu7u7smXLZunxx9/oGQBgWEwgBoCsZ/DgwQoKCtL+/ftVokQJyzChatWqMVckBYQBAIbGBGIAyFpsbGzk7e2tPn36qHnz5ipWrJi1S3qmEQYAQEnXqEbW1759e3Xq1EnVqlWzdikA0tjBgwe1adMmBQUFacuWLbKzs7P0DtSoUYNw8C+EAQD4h7179+r48eOSpICAAJUvX97KFSE9NG3aVKtWrVKBAgXUsWNHtW/f3rKUMICs5eDBg5o0aZK+/fZbJSYmMuzzXwgDACDpxo0batOmjYKCguTu7i5JCg8PV82aNbVkyRImnWVBN2/e1OLFi7Vw4UIdO3ZMderUUadOndSkSZNkVyQGkHmYzWbt379fQUFBCgoK0tatWxUZGanSpUurevXqmjRpkrVLfKYQBgBAUuvWrXXu3DktWrRIJUqUkCQdO3ZM7du3V5EiRfT9999buUKkp3379mn+/Pn6+uuv5ezsrLfeekvdu3dnTXIgE/Lw8FBUVJTKlCljGR5UtWpVyxc9SIowAACS3NzctG7dOlWsWDFJ+65du1S3bl2Fh4dbpzCku5CQEC1atEjz58/X5cuX1aJFC125ckWbNm3SuHHj1KdPH2uXCOAxrFy5UlWrVpWrq6u1S8kUuM4AAEhKTExMcWhI9uzZlZiYaIWKkJ7i4uK0YsUKzZ8/X2vXrlXp0qXVu3dvtW3b1vIB4pdfftE777xDGAAymYYNG1q7hEyFngEAkNSkSROFh4fr+++/V968eSU9uHrlm2++KQ8PD/3yyy9WrhBpKWfOnEpMTNQbb7yhzp07q2zZssn2CQ8PV7ly5XT+/PmMLxDAY2nevHmq9122bFk6VpL50DMAAJKmT5+uxo0by8/PT/ny5ZMkXbp0SaVKldI333xj5eqQ1iZNmqSWLVvKwcHhofu4u7sTBIBMws3NzfJvs9msX375RW5ubqpQoYKkByvFhYeHP1ZoMAp6BgDg/5nNZq1bt04nTpyQJJUoUUJ16tSxclUAgMcxcOBAhYWFadasWbK1tZUkJSQkqHv37nJ1ddUXX3xh5QqfLYQBAIAhMIwAMAZvb29t3bpV/v7+SdpPnjypl19+WaGhoVaq7NlkY+0CAMCaNmzYoICAAEVGRibbFhERoZIlS2rLli1WqAxpzc3NLdU3AJlXfHy8pYf3n06cOMGCEClgzgAAQ5s8ebI6d+6c4hJ0bm5u6tq1qyZOnKiqVataoTqkpfnz50t6MBzs0qVL8vb2Vo4cOaxcFYC01rFjR3Xq1Elnz57VCy+8IEnauXOnPv/8c3Xs2NHK1T17GCYEwNAKFCig1atXWy409m8nTpxQ3bp1FRwcnMGVIb0kJibKwcFBR48e5aJiQBaUmJio8ePHa8qUKQoJCdH/tXf3MVXW/x/HX9cQEDgwsIKQuD+l2MgiM90qYCMFV8NYqy0zsJulghkpAmtNiwW0xlY6BmwqQjcuSmOKbGRMEFq1JvMukcLhTc2ZE6UAAbn5/uE8v9/Jm7SAc/B6PjY2rutznet6cxiDF587SQoMDNTKlSu1atUq2zwCXEYYAGBqkydP1uHDh2W1Wq/Z3t7erujoaF28eHGcK8NYuv/++7Vp0ybNmTPH0aUAGENXhoCyAdn1MWcAgKkFBQXp8OHD120/ePCgAgMDx7EijIfCwkJlZWXd8HsPYOLz8fEhCPwDegYAmNqKFSvU0NCgn3766ao15y9evKjZs2crPj5e69evd1CFGAt+fn7q7e3V4OCg3Nzcrpo70NnZ6aDKAPxXZ86c0erVq1VfX68//vhDf/9Td2hoyEGVOSfCAABTO3PmjGJiYuTi4qKMjAzbUnRHjx5VcXGxhoaG1NLSooCAAAdXitFUUVFxw/bU1NRxqgTAaEtKStLJkyeVkZGhwMBAGYZh156cnOygypwTYQCA6Z04cULLli1TXV2d7T9IhmFo/vz5Ki4uVnh4uIMrBADcLG9vbzU1NenBBx90dCkTAkuLAjC90NBQ1dbW6vz582pvb9fIyIjuvfde+fn5Obo0jIO+vj4NDAzYnWOMMTBxBQcHXzU0CNdHzwAAwHR6enqUnZ2tqqqqa+5GyphiYOL65ptvVFRUpLKyMoWFhTm6HKdHzwAAwHTWrFmjPXv2qKSkRIsXL1ZxcbF+//13lZWVqbCw0NHlAfgPnn/+efX29ioyMlKenp5ydXW1a2eBAHv0DAAATCckJESVlZWKi4uTj4+PWlpaZLVa9cknn2jr1q2qra11dIkA/iUWCLg1hAEAgOlYLBYdOXJEISEhuueee7R9+3bNnj1bHR0dio6OVnd3t6NLBIBxwaZjAADTiYiIUEdHhyRp+vTpqqqqkiTt3LlTvr6+DqwMwGjq6+vTn3/+afcBe4QBAIDpLFmyRAcOHJAk5eTkqLi4WJMnT1ZmZqaysrIcXB2A/6Knp0cZGRny9/eXl5eX/Pz87D5gj2FCAADTO3HihPbt2yer1aoHHnjA0eUA+A/S09O1Z88e5eXlXXOBgEWLFjm6RKdCGAAAAMBtgwUCbg3DhAAAprFgwQJ1dXXZjgsLC3XhwgXb8blz5zRjxgwHVAZgtHR2dioiIkLS5Q0Erywl+thjj2nv3r2OLM0pEQYAAKZRV1en/v5+23F+fr7dmuODg4Nqa2tzRGkARgkLBNwawgAAwDT+PjKWkbLA7YcFAm4NOxADAADgtpGZmWn7PCEhQa2trbZ5AywQcDXCAADANAzDkGEYV50DcPsKCwtTWFiYo8twWoQBAIBpjIyMKC0tTe7u7pIub0i0dOlSeXl5SZLdfAIAE8v333+vc+fO6amnnrKdq6ys1Nq1a9XT06OFCxdqw4YNtp9/XMbSogAA01iyZMlNXVdeXj7GlQAYbUlJSYqLi1N2drYk6dChQ4qJiVFaWpqioqL04Ycf6vXXX9e6descW6iTIQwAAABgwgsMDNTOnTs1a9YsSdLbb7+txsZGNTc3S5K+/PJLrV27VkeOHHFkmU6H1YQAAAAw4Z0/f14BAQG248bGRiUlJdmOH3nkEZ06dcoRpTk1wgAAAAAmvICAANv+AgMDA2ppadGcOXNs7X/99ZdcXV0dVZ7TIgwAAABgwluwYIFycnLU1NSk3NxceXp66vHHH7e1Hzx4UJGRkQ6s0DmxmhAAAAAmvLy8PKWkpCg2NlYWi0UVFRVyc3OztW/evFnz5s1zYIXOiQnEAAAAuG10dXXJYrHIxcXF7nxnZ6csFotdQABhAAAAADAt5gwAAAAAJkUYAAAAAEyKMAAAAACYFGEAAAAAMCnCAADAVNLS0rRw4ULbcVxcnN58881xr6OhoUGGYejChQvj/mwAuIIwAABwCmlpaTIMQ4ZhyM3NTVarVe+9954GBwfH9Lnbt29XXl7eTV3LH/AAbjdsOgYAcBqJiYkqLy9Xf3+/amtrlZ6eLldXV+Xm5tpdNzAwMGprhU+ZMmVU7gMAExE9AwAAp+Hu7q67775boaGhWrZsmRISErRjxw7b0J73339fU6dO1bRp0yRJp06d0nPPPSdfX19NmTJFycnJOn78uO1+Q0NDeuutt+Tr66s77rhDa9as0d+31/n7MKH+/n5lZ2crODhY7u7uslqt2rRpk44fP674+HhJkp+fnwzDUFpamiRpeHhYBQUFCg8Pl4eHh2bOnKmvvvrK7jm1tbW677775OHhofj4eLs6AcBRCAMAAKfl4eGhgYEBSVJ9fb3a2tq0e/du1dTU6NKlS5o/f768vb3V1NSk7777ThaLRYmJibbXFBUVacuWLdq8ebOam5vV2dmpr7/++obPfOmll7R161atX79era2tKisrk8ViUXBwsLZt2yZJamtr0+nTp/Xxxx9LkgoKClRZWanS0lL9/PPPyszM1IsvvqjGxkZJl0NLSkqKnn76ae3fv1+vvvqqcnJyxuptA4CbxjAhAIDTGRkZUX19verq6rRixQqdPXtWXl5e2rhxo2140Keffqrh4WFt3LhRhmFIksrLy+Xr66uGhgbNmzdPH330kXJzc5WSkiJJKi0tVV1d3XWf+8svv6iqqkq7d+9WQkKCJCkiIsLWfmVIkb+/v3x9fSVd7knIz8/Xt99+q7lz59pe09zcrLKyMsXGxqqkpESRkZEqKiqSJE2bNk2HDh3SBx98MIrvGgDcOsIAAMBp1NTUyGKx6NKlSxoeHtYLL7ygdevWKT09XdHR0XbzBA4cOKD29nZ5e3vb3aOvr0/Hjh1TV1eXTp8+rUcffdTWNmnSJM2aNeuqoUJX7N+/Xy4uLoqNjb3pmtvb29Xb26snn3zS7vzAwIAeeughSVJra6tdHZJswQEAHIkwAABwGvHx8SopKZGbm5umTp2qSZP+79eUl5eX3bXd3d16+OGH9dlnn111n7vuuutfPd/Dw+OWX9Pd3S1J2rVrl4KCguza3N3d/1UdADBeCAMAAKfh5eUlq9V6U9fGxMToiy++kL+/v3x8fK55TWBgoH788Uc98cQTkqTBwUHt27dPMTEx17w+Ojpaw8PDamxstA0T+v+u9EwMDQ3Zzs2YMUPu7u46efLkdXsUoqKitGPHDrtzP/zwwz9/kQAwxphADACYkBYtWqQ777xTycnJampqUkdHhxoaGvTGG2/ot99+kyStXLlShYWFqq6u1tGjR7V8+fIb7hEQFham1NRUvfzyy6qurrbds6qqSpIUGhoqwzBUU1Ojs2fPqru7W97e3lq9erUyMzNVUVGhY8eOqaWlRRs2bFBFRYUkaenSpfr111+VlZWltrY2ff7559qyZctYv0UA8I8IAwCACcnT01N79+5VSEiIUlJSFBUVpVdeeUV9fX22noJVq1Zp8eLFSk1N1dy5c+Xt7a1nnnnmhvctKSnRs88+q+XLl2v69Ol67bXX1NPTI0kKCgrSu+++q5ycHAUEBCgjI0OSlJeXp3feeUcFBQWKiopSYmKidu3apfDwcElSSEiItm3bpurqas2cOVOlpaXKz88fw3cHAG6OMXK9WVQAAAAAbmv0DAAAAAAmRRgAAAAATIowAAAAAJgUYQAAAAAwKcIAAAAAYFKEAQAAAMCkCAMAAACASREGAAAAAJMiDAAAAAAmRRgAAAAATIowAAAAAJjU/wAD4SUbrCm4yAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set_seed(503)\n",
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "learning_rate = 0.0001\n",
    "model = DownstreamResNet(ssl_model, num_classes=5).to(device)\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).long()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).long()\n",
    "train_dataset = TensorDataset(X_train.transpose(1,2), y_train)\n",
    "test_dataset = TensorDataset(X_test.transpose(1,2), y_test)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset\n",
    "    , batch_size=batch_size,\n",
    "    shuffle=True, num_workers=4)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset\n",
    "    , batch_size=batch_size,\n",
    "    shuffle=False, num_workers=4)\n",
    "\n",
    "# Using Mean Squared Error loss for a regression problem\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "train_model(model, trainloader, criterion, optimizer, num_epochs=num_epochs, scheduler=scheduler)\n",
    "acc = test_model(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b754aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_mask(x, mask_ratio=0.5, patch_size=8):\n",
    "    \"\"\"\n",
    "    Masks blocks of the input time-series.\n",
    "    x: [Batch, Channels, Time]\n",
    "    Returns: \n",
    "        x_masked: Input with zeros in masked locations\n",
    "        mask: Binary mask [Batch, 1, Time] (1 = masked, 0 = visible)\n",
    "    \"\"\"\n",
    "    N, C, L = x.shape\n",
    "    num_patches = L // patch_size\n",
    "    num_masked = int(num_patches * mask_ratio)\n",
    "    mask = torch.zeros(N, num_patches, device=x.device)\n",
    "    noise = torch.rand(N, num_patches, device=x.device)\n",
    "    _, masked_indices = torch.topk(noise, num_masked, dim=1)\n",
    "    mask.scatter_(1, masked_indices, 1)\n",
    "    mask = mask.unsqueeze(1)\n",
    "    mask = F.interpolate(mask, size=L, mode='nearest')\n",
    "    x_masked = x * (1 - mask)\n",
    "    \n",
    "    return x_masked, mask\n",
    "\n",
    "# ==========================================\n",
    "# 2. Basic Components (Your Code + Fixes)\n",
    "# ==========================================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ==========================================\n",
    "# 3. The Multi-Task Model\n",
    "# ==========================================\n",
    "class MultiTaskResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=6):\n",
    "        super(MultiTaskResNet, self).__init__()\n",
    "        self.in_planes = 32 \n",
    "        \n",
    "        # --- Shared Encoder (ResNet-8) ---\n",
    "        self.initial_bn = nn.BatchNorm1d(in_channels)\n",
    "        # Stem: downsample factor 2 (stride 2) + maxpool factor 2 = total 4? \n",
    "        # Note: Your original code had stride 2 in conv1 AND maxpool stride 2.\n",
    "        # That is extremely aggressive downsampling for short sensor windows.\n",
    "        # I relaxed conv1 stride to 1 to preserve more temporal info.\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1) # Downsample /2\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock1D, 32,  blocks=1, stride=1) \n",
    "        self.layer2 = self._make_layer(BasicBlock1D, 64,  blocks=1, stride=2) # Downsample /4\n",
    "        self.layer3 = self._make_layer(BasicBlock1D, 128, blocks=1, stride=2) # Downsample /8\n",
    "\n",
    "        self.maxxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # --- Discriminative Heads (Task B: Pretext Classification) ---\n",
    "        # These use the POOLED features (global context)\n",
    "        self.head_reverse = nn.Linear(128, 1)\n",
    "        self.head_permute = nn.Linear(128, 1)\n",
    "        self.head_warp    = nn.Linear(128, 1)\n",
    "\n",
    "        # --- Generative Head (Task A: Reconstruction) ---\n",
    "        # This uses the SPATIAL features (local context)\n",
    "        # Input: [Batch, 128, L/8] -> Output: [Batch, in_channels, L]\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Upsample 1: T/8 -> T/4\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Upsample 2: T/4 -> T/2\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Upsample 3: T/2 -> T (Matches maxpool)\n",
    "            nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Final Projection to Input Channels\n",
    "            nn.Conv1d(32, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward_encoder(self, x):\n",
    "        \"\"\"Returns both spatial features (for MAE) and pooled features (for Classif)\"\"\"\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        spatial_feat = self.layer3(x) # [B, 128, T_small]\n",
    "\n",
    "        pooled_feat = self.maxxpool(spatial_feat) # [B, 128, 1]\n",
    "        pooled_feat = torch.flatten(pooled_feat, 1) # [B, 128]\n",
    "        \n",
    "        return spatial_feat, pooled_feat\n",
    "\n",
    "    def forward(self, x, task='all', mask_ratio=0.0):\n",
    "        \"\"\"\n",
    "        task: 'all' (pretraining), 'mae_only', 'class_only', or 'downstream'\n",
    "        \"\"\"\n",
    "        if task == 'downstream':\n",
    "            # Just return features for fine-tuning\n",
    "            _, pooled = self.forward_encoder(x)\n",
    "            return pooled\n",
    "\n",
    "        # 1. MAE Branch\n",
    "        # Apply mask to input\n",
    "        x_masked, mask = apply_mask(x, mask_ratio=mask_ratio)\n",
    "        \n",
    "        # Encode\n",
    "        # Important: We pass the MASKED input to the encoder\n",
    "        spatial, pooled = self.forward_encoder(x_masked)\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Reconstruction Output\n",
    "        recon_x = self.decoder(spatial)\n",
    "        outputs['recon'] = recon_x\n",
    "        outputs['mask'] = mask # Needed for loss calculation\n",
    "\n",
    "        # 2. Classification Branch\n",
    "        # In a real loop, you might feed different batches (x_transformed) here\n",
    "        # For simplicity, we assume x might be transformed before entering forward\n",
    "        outputs['reverse'] = self.head_reverse(pooled)\n",
    "        outputs['permute'] = self.head_permute(pooled)\n",
    "        outputs['warp'] = self.head_warp(pooled)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# ==========================================\n",
    "# 4. Loss Function Example\n",
    "# ==========================================\n",
    "def multitask_loss(outputs, original_x, labels_reverse, labels_permute, labels_warp):\n",
    "    \"\"\"\n",
    "    Combines Reconstruction Loss and Classification Loss\n",
    "    \"\"\"\n",
    "    # 1. MAE Loss (MSE) - Only on masked regions!\n",
    "    recon = outputs['recon']\n",
    "    mask = outputs['mask']\n",
    "    \n",
    "    # Ensure shapes match (Decoder output might be slightly off due to padding)\n",
    "    if recon.shape[-1] != original_x.shape[-1]:\n",
    "        recon = F.interpolate(recon, size=original_x.shape[-1])\n",
    "        \n",
    "    # Loss = ||(x - x_hat) * mask||^2\n",
    "    # We only care about errors where mask == 1\n",
    "    loss_recon = (original_x - recon) ** 2\n",
    "    loss_recon = (loss_recon * mask).sum() / (mask.sum() + 1e-8) # Normalize by number of masked pixels\n",
    "\n",
    "    # 2. Classification Losses (BCE)\n",
    "    loss_rev = F.binary_cross_entropy_with_logits(outputs['reverse'], labels_reverse)\n",
    "    loss_perm = F.binary_cross_entropy_with_logits(outputs['permute'], labels_permute)\n",
    "    loss_warp = F.binary_cross_entropy_with_logits(outputs['warp'], labels_warp)\n",
    "    \n",
    "    # Weighted Sum (Tune lambda as needed)\n",
    "    lambda_mae = 1.0\n",
    "    lambda_cls = 0.5\n",
    "    \n",
    "    total_loss = lambda_mae * loss_recon + lambda_cls * (loss_rev + loss_perm + loss_warp)\n",
    "    \n",
    "    return total_loss, loss_recon, (loss_rev+loss_perm+loss_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edebbd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Weight: 2.1150, Min Weight: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return F.linear(input, self.weight, self.bias)\n",
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Total: 0.8134 | Recon: 149.9784 | Class: 0.7984\n",
      "Epoch [2/10] Total: 0.4464 | Recon: 139.8799 | Class: 0.4324\n",
      "Epoch [3/10] Total: 0.3640 | Recon: 136.8638 | Class: 0.3503\n",
      "Epoch [4/10] Total: 0.3099 | Recon: 134.5263 | Class: 0.2965\n",
      "Epoch [5/10] Total: 0.2791 | Recon: 132.7530 | Class: 0.2659\n",
      "Epoch [6/10] Total: 0.2638 | Recon: 131.9068 | Class: 0.2506\n",
      "Epoch [7/10] Total: 0.2402 | Recon: 130.4019 | Class: 0.2271\n",
      "Epoch [8/10] Total: 0.2230 | Recon: 131.8688 | Class: 0.2098\n",
      "Epoch [9/10] Total: 0.2101 | Recon: 127.7937 | Class: 0.1973\n",
      "Epoch [10/10] Total: 0.2032 | Recon: 129.4453 | Class: 0.1902\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "N_SAMPLES = X.shape[0]\n",
    "SEQ_LEN = X.shape[1]\n",
    "CHANNELS = X.shape[2]\n",
    "\n",
    "\n",
    "std_per_channel = torch.std(X.transpose(1,2), dim=2)\n",
    "\n",
    "sample_weights = std_per_channel.mean(dim=1)\n",
    "\n",
    "sample_weights = sample_weights + 1e-6\n",
    "\n",
    "print(f\"Max Weight: {sample_weights.max():.4f}, Min Weight: {sample_weights.min():.4f}\")\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "ssl_model = MultiTaskResNet(in_channels=CHANNELS).to(device)\n",
    "optimizer = optim.Adam(ssl_model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "dataset = TensorDataset(X.transpose(1,2), y)\n",
    "loader = DataLoader(dataset, batch_size=32, sampler = sampler, shuffle=False)\n",
    "EPOCHS_SSL = 10\n",
    "weight = [0.0001, 1]\n",
    "ssl_model.train()\n",
    "for epoch in range(EPOCHS_SSL):\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_class_loss = 0\n",
    "    for x_batch, _ in loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = ssl_model(x_batch, task = 'mae_only', mask_ratio = 0.5)\n",
    "        reverse = outputs['reverse']\n",
    "        permute  = outputs['permute']\n",
    "        warp = outputs['warp']\n",
    "        dummy = torch.zeros(x_batch.size(0), device=device).reshape(-1, 1)\n",
    "        \n",
    "        _, loss_recon, _ = multitask_loss(outputs, x_batch, dummy, dummy, dummy)\n",
    "        x_aug, l_rev, l_perm, l_warp = generate_ssl_batch(x_batch)\n",
    "        outputs_cls = ssl_model(x_aug, task='class_only', mask_ratio=0.0)\n",
    "        # print(l_rev)\n",
    "        l_rev = l_rev.to(\"cuda\")\n",
    "        l_perm = l_perm.to(\"cuda\")\n",
    "        l_warp = l_warp.to(\"cuda\")\n",
    "        _, _, loss_class = multitask_loss(outputs_cls, x_aug, l_rev, l_perm, l_warp)\n",
    "        loss = (weight[0] * loss_recon) + (weight[1] * loss_class)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_recon_loss += loss_recon.item()\n",
    "        total_class_loss += loss_class.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_recon = total_recon_loss / len(loader)\n",
    "    avg_class = total_class_loss / len(loader)    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS_SSL}] Total: {avg_loss:.4f} | Recon: {avg_recon:.4f} | Class: {avg_class:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d71992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Tests the trained model and prints the parameter count and final accuracy.\n",
    "    \"\"\"\n",
    "    print(f\"\\nNumber of model parameters is: {count_parameters(model)}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_test = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
    "            y_test = np.append(y_test, labels.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8194d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pre-trained SSL Weights...\n",
      "--- Setting Global Seed: 130 ---\n",
      "\n",
      "Phase 1: Linear Probing (Encoder Frozen)\n",
      "Epoch 1/3 | Loss: 1.3247 | Acc: 47.82%\n",
      "Epoch 2/3 | Loss: 1.1523 | Acc: 55.69%\n",
      "Epoch 3/3 | Loss: 1.0979 | Acc: 57.43%\n",
      "\n",
      "Phase 2: Full Fine-Tuning (Encoder Unfrozen)\n",
      "Epoch 1/3 | Loss: 0.8016 | Acc: 68.31%\n",
      "Epoch 2/3 | Loss: 0.5816 | Acc: 76.10%\n",
      "Epoch 3/3 | Loss: 0.4990 | Acc: 79.61%\n",
      "\n",
      "Number of model parameters is: 189253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6558732345849122\n",
      "--- Setting Global Seed: 427 ---\n",
      "\n",
      "Phase 1: Linear Probing (Encoder Frozen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.3256 | Acc: 48.14%\n",
      "Epoch 2/3 | Loss: 1.1635 | Acc: 55.00%\n",
      "Epoch 3/3 | Loss: 1.1149 | Acc: 56.31%\n",
      "\n",
      "Phase 2: Full Fine-Tuning (Encoder Unfrozen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 0.8022 | Acc: 67.86%\n",
      "Epoch 2/3 | Loss: 0.5965 | Acc: 75.28%\n",
      "Epoch 3/3 | Loss: 0.4959 | Acc: 79.49%\n",
      "\n",
      "Number of model parameters is: 189253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.611091973820186\n",
      "--- Setting Global Seed: 200 ---\n",
      "\n",
      "Phase 1: Linear Probing (Encoder Frozen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.3421 | Acc: 47.57%\n",
      "Epoch 2/3 | Loss: 1.1419 | Acc: 56.19%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPhase 1: Linear Probing (Encoder Frozen)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m optimizer_head = optim.Adam(model.fc.parameters(), lr=\u001b[32m0.001\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43mfine_tune_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPhase 2: Full Fine-Tuning (Encoder Unfrozen)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m model.unfreeze_encoder_weights()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mfine_tune_train\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device, epochs)\u001b[39m\n\u001b[32m     41\u001b[39m outputs = model(x_batch.transpose(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m))\n\u001b[32m     42\u001b[39m loss = criterion(outputs, y_batch)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m optimizer.step()\n\u001b[32m     46\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class DownstreamClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps the pre-trained SSL model to perform classification.\n",
    "    Discards the Decoder and Pretext heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_model, num_classes, freeze_encoder=False):\n",
    "        super(DownstreamClassifier, self).__init__()\n",
    "        self.encoder = pretrained_model\n",
    "        # Create a new classification head\n",
    "        # The encoder outputs 128-dim pooled features\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "        if freeze_encoder:\n",
    "            self.freeze_encoder_weights()\n",
    "\n",
    "    def freeze_encoder_weights(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_encoder_weights(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We only use the 'downstream' task to get pooled features\n",
    "        features = self.encoder(x, task='downstream')\n",
    "        logits = self.fc(features)\n",
    "        return logits\n",
    "\n",
    "def fine_tune_train(model, loader, optimizer, criterion, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch.transpose(1,2))\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(loader):.4f} | Acc: {100 * correct / total:.2f}%\")\n",
    "seed = [130, 427, 200, 104, 110, 36, 503, 1028, 409, 1130]\n",
    "if __name__ == \"__main__\":\n",
    "    result = np.zeros((20, 4))\n",
    "    k = 0\n",
    "    for i in range(4):\n",
    "        X = [X1_test, X2_test, X3_test, X4_test]\n",
    "        y = [y1_test, y2_test, y3_test, y4_test]\n",
    "        X_test = X.pop(i)\n",
    "        y_test = y.pop(i)\n",
    "        X_train = torch.concatenate(X, axis = 0)\n",
    "        y_train = torch.concatenate(y, axis = 0)\n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # 2. Load Pre-trained Model\n",
    "        print(\"Loading Pre-trained SSL Weights...\")\n",
    "        ssl_model = MultiTaskResNet(in_channels=CHANNELS).to(device)\n",
    "        initial_state = copy.deepcopy(ssl_model.state_dict())\n",
    "        # 3. Initialize Fine-Tuning Model\n",
    "        NUM_CLASSES = 5\n",
    "        for j in range(5):\n",
    "            ssl_model.load_state_dict(initial_state)\n",
    "            set_seed(seed[j])\n",
    "            model = DownstreamClassifier(ssl_model, NUM_CLASSES, freeze_encoder=True).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            class_counts = torch.bincount(y_train)\n",
    "            weights = 1. / class_counts.float()\n",
    "            weights = weights / weights.sum()\n",
    "            criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "            print(\"\\nPhase 1: Linear Probing (Encoder Frozen)\")\n",
    "            optimizer_head = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "            fine_tune_train(model, loader, optimizer_head, criterion, device, epochs=3)\n",
    "            print(\"\\nPhase 2: Full Fine-Tuning (Encoder Unfrozen)\")\n",
    "            model.unfreeze_encoder_weights()\n",
    "            optimizer_all = optim.Adam([\n",
    "                {'params': model.encoder.parameters(), 'lr': 1e-4}, # Low LR\n",
    "                {'params': model.fc.parameters(),      'lr': 1e-3}  # High LR\n",
    "            ])\n",
    "            fine_tune_train(model, loader, optimizer_all, criterion, device, epochs=3)\n",
    "            X_test = torch.tensor(X_test).float()\n",
    "            y_test = torch.tensor(y_test).long()\n",
    "            test_dataset = TensorDataset(X_test.transpose(1,2), y_test)\n",
    "            testloader = torch.utils.data.DataLoader(test_dataset\n",
    "                , batch_size=16,\n",
    "                shuffle=False, num_workers=4)\n",
    "            accuracy, precision, recall, f1 = test_model(model, testloader)\n",
    "            result[k, 0] = accuracy\n",
    "            result[k, 1] = precision\n",
    "            result[k, 2] = recall\n",
    "            result[k, 3] = f1\n",
    "            print(accuracy)\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd211752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67516362, 0.69141506, 0.67516362, 0.67552376],\n",
       "       [0.62831554, 0.63274176, 0.62831554, 0.62683534],\n",
       "       [0.64760592, 0.67468794, 0.64760592, 0.64913281],\n",
       "       [0.63107131, 0.65095831, 0.63107131, 0.62951672],\n",
       "       [0.60179125, 0.61721082, 0.60179125, 0.60028354],\n",
       "       [0.67280306, 0.67101782, 0.67280306, 0.66725203],\n",
       "       [0.66724557, 0.71641588, 0.66724557, 0.67554454],\n",
       "       [0.67176103, 0.6732993 , 0.67176103, 0.6690899 ],\n",
       "       [0.62348038, 0.66041742, 0.62348038, 0.62333217],\n",
       "       [0.67002431, 0.6691605 , 0.67002431, 0.65780479],\n",
       "       [0.55921856, 0.64853352, 0.55921856, 0.56452608],\n",
       "       [0.59259259, 0.63590892, 0.59259259, 0.58261039],\n",
       "       [0.60805861, 0.6208062 , 0.60805861, 0.60098188],\n",
       "       [0.58974359, 0.63552584, 0.58974359, 0.58547731],\n",
       "       [0.57102157, 0.66124576, 0.57102157, 0.56856745],\n",
       "       [0.64031079, 0.64667003, 0.64031079, 0.63508787],\n",
       "       [0.6179159 , 0.63678087, 0.6179159 , 0.61095958],\n",
       "       [0.67778793, 0.68604077, 0.67778793, 0.67250244],\n",
       "       [0.65722121, 0.65993177, 0.65722121, 0.65051363],\n",
       "       [0.66407678, 0.66632687, 0.66407678, 0.66243701]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28052bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6489262 , 0.66573248, 0.6489262 , 0.64743156])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427f6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01777658, 0.01905431, 0.01777658, 0.01766918])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "np.std(result, axis = 0)/np.sqrt(10   )*stats.t.ppf(0.975, df=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
