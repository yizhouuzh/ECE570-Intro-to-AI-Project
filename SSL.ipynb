{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc7a9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import optuna\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6db786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    Sets seeds and forces deterministic algorithms.\n",
    "    \"\"\"\n",
    "    print(f\"--- Setting Global Seed: {seed} ---\")\n",
    "    \n",
    "    # 1. Set Env Var for Deterministic Algorithms (Must be before torch usage)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    \n",
    "    # 2. Python & Numpy\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 3. PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    \n",
    "    # 4. Force Deterministic Algorithms\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # New in PyTorch 1.8+ - throws error if an operation is non-deterministic\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    except AttributeError:\n",
    "        pass # Older pytorch versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d491c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segmentation(df, y_label, window_size = 100, stride = 50):\n",
    "    '''\n",
    "    Segments the data into the same length and detach the whole dataset into X and y.\n",
    "    \n",
    "    df: data frame that contains all covariates and response variables\n",
    "    y_label: the column name of the response variable that we want to predict\n",
    "    window_size: the length of time included in a single data point\n",
    "    stride: The interval between two closest segmented data point\n",
    "    '''\n",
    "    j = df.columns.get_loc(y_label)\n",
    "    data = df.to_numpy()\n",
    "    n = len(data)\n",
    "    X = []\n",
    "    y = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    while start <= n - window_size:\n",
    "        end = start + window_size - 1\n",
    "        if data[start][j] == data[end][j] and data[start][0] + 0.01 > data[end][0] and data[start][j]!=0:\n",
    "            X.append(data[start:(end+1),1:-7])\n",
    "            y.append(data[start][j])\n",
    "            start += stride\n",
    "        else:\n",
    "            while start + window_size - 1 < n:\n",
    "                if data[start][j] != data[start+1][j]:\n",
    "                    break\n",
    "                start += 1\n",
    "            start += 1\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e1aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Returns the total number of trainable parameters in the model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "def train_model(model, data_loader, criterion, optimizer, num_epochs, scheduler=None, print_every_n_batches=100):\n",
    "    \"\"\"\n",
    "    Trains the model and prints the parameter count and running loss periodically.\n",
    "    Accepts an optional scheduler.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nNumber of model parameters is: {count_parameters(model)}\")\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % print_every_n_batches == 0:\n",
    "                avg_loss = running_loss / print_every_n_batches\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}] | Batch [{i+1}/{len(data_loader)}] | Running Loss: {avg_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "                running_loss = 0.0\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    print(\"\\nFinished Training.\")\n",
    "    return model\n",
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Tests the trained model and prints the parameter count and final accuracy.\n",
    "    \"\"\"\n",
    "    print(f\"\\nNumber of model parameters is: {count_parameters(model)}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_test = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
    "            y_test = np.append(y_test, labels.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "        # Print the evaluation metrics\n",
    "        print(\"Accuracy:\", f\"{accuracy:.4f}\")\n",
    "        print(\"Precision:\", f\"{precision:.4f}\")\n",
    "        print(\"Recall:\", f\"{recall:.4f}\")\n",
    "        print(\"F1 Score:\", f\"{f1:.4f}\")\n",
    "        print(f\"\\nTest accuracy of model: {accuracy*100:.2f}%\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # plot the confusion matrix\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\n",
    "        plt.xticks(np.arange(5)+0.5, ['Relaxing', 'Coffee time', 'Early morning', 'Cleanup', 'Sandwich time'], rotation=90)\n",
    "        plt.yticks(np.arange(5)+0.5, ['Relaxing', 'Coffee time', 'Early morning', 'Cleanup', 'Sandwich time'], rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "911953ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentations:\n",
    "    @staticmethod\n",
    "    def reverse(x):\n",
    "        \"\"\"\n",
    "        Reverses time dim.\n",
    "        Input: (B, C, L)\n",
    "        \"\"\"\n",
    "        return torch.flip(x, dims=[-1])\n",
    "\n",
    "    @staticmethod\n",
    "    def permute(x, segments=4):\n",
    "        \"\"\"\n",
    "        Splits time series into segments and shuffles them randomly.\n",
    "        \n",
    "        CRITICAL FOR MULTI-SENSOR DATA:\n",
    "        We shuffle the segments of ALL channels (C) synchronously.\n",
    "        If we shuffled channel 0 differently from channel 1, we would destroy\n",
    "        the inter-feature correlations (e.g., the relationship between \n",
    "        accelerometer and gyroscope).\n",
    "        \"\"\"\n",
    "        B, C, L = x.shape\n",
    "        segment_len = L // segments\n",
    "        effective_len = segment_len * segments\n",
    "        x_trimmed = x[:, :, :effective_len]\n",
    "        x_reshaped = x_trimmed.view(B, C, segments, segment_len)\n",
    "        rand_inds = torch.argsort(torch.rand(B, segments, device=x.device), dim=1)\n",
    "        expanded_inds = rand_inds.view(B, 1, segments, 1).expand(B, C, segments, segment_len)\n",
    "        x_permuted = torch.gather(x_reshaped, 2, expanded_inds)\n",
    "        return x_permuted.reshape(B, C, effective_len)\n",
    "\n",
    "    @staticmethod\n",
    "    def time_warp(x, sigma=0.2, num_knots=4):\n",
    "        \"\"\"\n",
    "        Simulates time warping by stretching and squeezing time.\n",
    "        \n",
    "        CRITICAL FOR MULTI-SENSOR DATA:\n",
    "        We generate ONE warp flow per sample and apply it to ALL channels.\n",
    "        \"\"\"\n",
    "        B, C, L = x.shape\n",
    "        device = x.device\n",
    "        warped_batch = []\n",
    "        \n",
    "        for i in range(B):\n",
    "            ratio = np.random.uniform(0.5, 1.5)\n",
    "            new_len = int(L * ratio)\n",
    "            signal_tensor = x[i].unsqueeze(0) \n",
    "            warped = F.interpolate(signal_tensor, size=new_len, mode='linear', align_corners=False)\n",
    "            if new_len > L:\n",
    "                start = np.random.randint(0, new_len - L)\n",
    "                restored = warped[:, :, start:start+L]\n",
    "            else:\n",
    "                padding = L - new_len\n",
    "                restored = F.pad(warped, (0, padding), \"constant\", 0)\n",
    "            warped_batch.append(restored.squeeze(0))\n",
    "            \n",
    "        return torch.stack(warped_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f938093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ssl_batch(x_batch):\n",
    "    \"\"\"\n",
    "    Returns batch augmented with binary labels for Multi-Task Learning.\n",
    "    Returns:\n",
    "        x_aug: (4*B, C, L)\n",
    "        y_rev: (4*B, 1)\n",
    "        y_perm: (4*B, 1)\n",
    "        y_warp: (4*B, 1)\n",
    "    \"\"\"\n",
    "    B, C, L = x_batch.shape\n",
    "    orig = x_batch.clone()\n",
    "    rev = Augmentations.reverse(x_batch)\n",
    "    perm = Augmentations.permute(x_batch)\n",
    "    warp = Augmentations.time_warp(x_batch)\n",
    "    \n",
    "    x_combined = torch.cat([orig, rev, perm, warp], dim=0)\n",
    "    l_rev = torch.cat([\n",
    "        torch.zeros(B), # Orig\n",
    "        torch.ones(B),  # Rev\n",
    "        torch.zeros(B), # Perm \n",
    "        torch.zeros(B)  # Warp \n",
    "    ]).unsqueeze(1)\n",
    "    l_perm = torch.cat([\n",
    "        torch.zeros(B),\n",
    "        torch.zeros(B),\n",
    "        torch.ones(B),  # Perm\n",
    "        torch.zeros(B)\n",
    "    ]).unsqueeze(1)\n",
    "    l_warp = torch.cat([\n",
    "        torch.zeros(B),\n",
    "        torch.zeros(B),\n",
    "        torch.zeros(B),\n",
    "        torch.ones(B)   # Warp\n",
    "    ]).unsqueeze(1)\n",
    "    idx = torch.randperm(x_combined.size(0))\n",
    "    return x_combined[idx], l_rev[idx], l_perm[idx], l_warp[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0449b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_S1 = pd.read_csv(\"S1.csv\")\n",
    "df_S2 = pd.read_csv(\"S2.csv\")\n",
    "df_S3 = pd.read_csv(\"S3.csv\")\n",
    "df_S4 = pd.read_csv(\"S4.csv\")\n",
    "X1_test, y1_test = data_segmentation(df_S1, \"HL_Activity\")\n",
    "X2_test, y2_test = data_segmentation(df_S2, \"HL_Activity\")\n",
    "X3_test, y3_test = data_segmentation(df_S3, \"HL_Activity\")\n",
    "X4_test, y4_test = data_segmentation(df_S4, \"HL_Activity\")\n",
    "y1_test -= 101\n",
    "y2_test -= 101\n",
    "y3_test -= 101\n",
    "y4_test -= 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6f5d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X1_test = torch.tensor(X1_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X2_test = torch.tensor(X2_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X3_test = torch.tensor(X3_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X4_test = torch.tensor(X4_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y1_test = torch.tensor(y1_test).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y2_test = torch.tensor(y2_test).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y3_test = torch.tensor(y3_test).long()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\1173063394.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y4_test = torch.tensor(y4_test).long()\n"
     ]
    }
   ],
   "source": [
    "X1_test = torch.tensor(X1_test).float()\n",
    "X2_test = torch.tensor(X2_test).float()\n",
    "X3_test = torch.tensor(X3_test).float()\n",
    "X4_test = torch.tensor(X4_test).float()\n",
    "y1_test = torch.tensor(y1_test).long()\n",
    "y2_test = torch.tensor(y2_test).long()\n",
    "y3_test = torch.tensor(y3_test).long()\n",
    "y4_test = torch.tensor(y4_test).long()\n",
    "X = torch.cat((X1_test, X2_test, X3_test, X4_test), dim = 0)\n",
    "y = torch.cat((y1_test, y2_test, y3_test, y4_test), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b754aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_mask(x, mask_ratio=0.5, patch_size=8):\n",
    "    \"\"\"\n",
    "    Masks blocks of the input time-series.\n",
    "    x: [Batch, Channels, Time]\n",
    "    Returns: \n",
    "        x_masked: Input with zeros in masked locations\n",
    "        mask: Binary mask [Batch, 1, Time] (1 = masked, 0 = visible)\n",
    "    \"\"\"\n",
    "    N, C, L = x.shape\n",
    "    num_patches = L // patch_size\n",
    "    num_masked = int(num_patches * mask_ratio)\n",
    "    mask = torch.zeros(N, num_patches, device=x.device)\n",
    "    noise = torch.rand(N, num_patches, device=x.device)\n",
    "    _, masked_indices = torch.topk(noise, num_masked, dim=1)\n",
    "    mask.scatter_(1, masked_indices, 1)\n",
    "    mask = mask.unsqueeze(1)\n",
    "    mask = F.interpolate(mask, size=L, mode='nearest')\n",
    "    x_masked = x * (1 - mask)\n",
    "    \n",
    "    return x_masked, mask\n",
    "\n",
    "# ==========================================\n",
    "# 2. Basic Components (Your Code + Fixes)\n",
    "# ==========================================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ==========================================\n",
    "# 3. The Multi-Task Model\n",
    "# ==========================================\n",
    "class MultiTaskResNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=6):\n",
    "        super(MultiTaskResNet, self).__init__()\n",
    "        self.in_planes = 32 \n",
    "        \n",
    "        # --- Shared Encoder (ResNet-8) ---\n",
    "        self.initial_bn = nn.BatchNorm1d(in_channels)\n",
    "        # Stem: downsample factor 2 (stride 2) + maxpool factor 2 = total 4? \n",
    "        # Note: Your original code had stride 2 in conv1 AND maxpool stride 2.\n",
    "        # That is extremely aggressive downsampling for short sensor windows.\n",
    "        # I relaxed conv1 stride to 1 to preserve more temporal info.\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1) # Downsample /2\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock1D, 32,  blocks=1, stride=1) \n",
    "        self.layer2 = self._make_layer(BasicBlock1D, 64,  blocks=1, stride=2) # Downsample /4\n",
    "        self.layer3 = self._make_layer(BasicBlock1D, 128, blocks=1, stride=2) # Downsample /8\n",
    "\n",
    "        self.maxxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # --- Discriminative Heads (Task B: Pretext Classification) ---\n",
    "        # These use the POOLED features (global context)\n",
    "        self.head_reverse = nn.Linear(128, 1)\n",
    "        self.head_permute = nn.Linear(128, 1)\n",
    "        self.head_warp    = nn.Linear(128, 1)\n",
    "\n",
    "        # --- Generative Head (Task A: Reconstruction) ---\n",
    "        # This uses the SPATIAL features (local context)\n",
    "        # Input: [Batch, 128, L/8] -> Output: [Batch, in_channels, L]\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Upsample 1: T/8 -> T/4\n",
    "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Upsample 2: T/4 -> T/2\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Upsample 3: T/2 -> T (Matches maxpool)\n",
    "            nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Final Projection to Input Channels\n",
    "            nn.Conv1d(32, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward_encoder(self, x):\n",
    "        \"\"\"Returns both spatial features (for MAE) and pooled features (for Classif)\"\"\"\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        spatial_feat = self.layer3(x) # [B, 128, T_small]\n",
    "\n",
    "        pooled_feat = self.maxxpool(spatial_feat) # [B, 128, 1]\n",
    "        pooled_feat = torch.flatten(pooled_feat, 1) # [B, 128]\n",
    "        \n",
    "        return spatial_feat, pooled_feat\n",
    "\n",
    "    def forward(self, x, task='all', mask_ratio=0.0):\n",
    "        \"\"\"\n",
    "        task: 'all' (pretraining), 'mae_only', 'class_only', or 'downstream'\n",
    "        \"\"\"\n",
    "        if task == 'downstream':\n",
    "            # Just return features for fine-tuning\n",
    "            _, pooled = self.forward_encoder(x)\n",
    "            return pooled\n",
    "\n",
    "        # 1. MAE Branch\n",
    "        # Apply mask to input\n",
    "        x_masked, mask = apply_mask(x, mask_ratio=mask_ratio)\n",
    "        \n",
    "        # Encode\n",
    "        # Important: We pass the MASKED input to the encoder\n",
    "        spatial, pooled = self.forward_encoder(x_masked)\n",
    "        \n",
    "        outputs = {}\n",
    "        \n",
    "        # Reconstruction Output\n",
    "        recon_x = self.decoder(spatial)\n",
    "        outputs['recon'] = recon_x\n",
    "        outputs['mask'] = mask # Needed for loss calculation\n",
    "\n",
    "        # 2. Classification Branch\n",
    "        # In a real loop, you might feed different batches (x_transformed) here\n",
    "        # For simplicity, we assume x might be transformed before entering forward\n",
    "        outputs['reverse'] = self.head_reverse(pooled)\n",
    "        outputs['permute'] = self.head_permute(pooled)\n",
    "        outputs['warp'] = self.head_warp(pooled)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# ==========================================\n",
    "# 4. Loss Function Example\n",
    "# ==========================================\n",
    "def multitask_loss(outputs, original_x, labels_reverse, labels_permute, labels_warp):\n",
    "    \"\"\"\n",
    "    Combines Reconstruction Loss and Classification Loss\n",
    "    \"\"\"\n",
    "    # 1. MAE Loss (MSE) - Only on masked regions!\n",
    "    recon = outputs['recon']\n",
    "    mask = outputs['mask']\n",
    "    \n",
    "    # Ensure shapes match (Decoder output might be slightly off due to padding)\n",
    "    if recon.shape[-1] != original_x.shape[-1]:\n",
    "        recon = F.interpolate(recon, size=original_x.shape[-1])\n",
    "        \n",
    "    # Loss = ||(x - x_hat) * mask||^2\n",
    "    # We only care about errors where mask == 1\n",
    "    loss_recon = (original_x - recon) ** 2\n",
    "    loss_recon = (loss_recon * mask).sum() / (mask.sum() + 1e-8) # Normalize by number of masked pixels\n",
    "\n",
    "    # 2. Classification Losses (BCE)\n",
    "    loss_rev = F.binary_cross_entropy_with_logits(outputs['reverse'], labels_reverse)\n",
    "    loss_perm = F.binary_cross_entropy_with_logits(outputs['permute'], labels_permute)\n",
    "    loss_warp = F.binary_cross_entropy_with_logits(outputs['warp'], labels_warp)\n",
    "    \n",
    "    # Weighted Sum (Tune lambda as needed)\n",
    "    lambda_mae = 1.0\n",
    "    lambda_cls = 0.5\n",
    "    \n",
    "    total_loss = lambda_mae * loss_recon + lambda_cls * (loss_rev + loss_perm + loss_warp)\n",
    "    \n",
    "    return total_loss, loss_recon, (loss_rev+loss_perm+loss_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edebbd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Weight: 2.1150, Min Weight: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return F.linear(input, self.weight, self.bias)\n",
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Total: 0.8134 | Recon: 149.9784 | Class: 0.7984\n",
      "Epoch [2/10] Total: 0.4464 | Recon: 139.8799 | Class: 0.4324\n",
      "Epoch [3/10] Total: 0.3640 | Recon: 136.8638 | Class: 0.3503\n",
      "Epoch [4/10] Total: 0.3099 | Recon: 134.5263 | Class: 0.2965\n",
      "Epoch [5/10] Total: 0.2791 | Recon: 132.7530 | Class: 0.2659\n",
      "Epoch [6/10] Total: 0.2638 | Recon: 131.9068 | Class: 0.2506\n",
      "Epoch [7/10] Total: 0.2402 | Recon: 130.4019 | Class: 0.2271\n",
      "Epoch [8/10] Total: 0.2230 | Recon: 131.8688 | Class: 0.2098\n",
      "Epoch [9/10] Total: 0.2101 | Recon: 127.7937 | Class: 0.1973\n",
      "Epoch [10/10] Total: 0.2032 | Recon: 129.4453 | Class: 0.1902\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "N_SAMPLES = X.shape[0]\n",
    "SEQ_LEN = X.shape[1]\n",
    "CHANNELS = X.shape[2]\n",
    "\n",
    "\n",
    "std_per_channel = torch.std(X.transpose(1,2), dim=2)\n",
    "\n",
    "sample_weights = std_per_channel.mean(dim=1)\n",
    "\n",
    "sample_weights = sample_weights + 1e-6\n",
    "\n",
    "print(f\"Max Weight: {sample_weights.max():.4f}, Min Weight: {sample_weights.min():.4f}\")\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "ssl_model = MultiTaskResNet(in_channels=CHANNELS).to(device)\n",
    "optimizer = optim.Adam(ssl_model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "dataset = TensorDataset(X.transpose(1,2), y)\n",
    "loader = DataLoader(dataset, batch_size=32, sampler = sampler, shuffle=False)\n",
    "EPOCHS_SSL = 10\n",
    "weight = [0.0001, 1]\n",
    "ssl_model.train()\n",
    "for epoch in range(EPOCHS_SSL):\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_class_loss = 0\n",
    "    for x_batch, _ in loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = ssl_model(x_batch, task = 'mae_only', mask_ratio = 0.5)\n",
    "        reverse = outputs['reverse']\n",
    "        permute  = outputs['permute']\n",
    "        warp = outputs['warp']\n",
    "        dummy = torch.zeros(x_batch.size(0), device=device).reshape(-1, 1)\n",
    "        \n",
    "        _, loss_recon, _ = multitask_loss(outputs, x_batch, dummy, dummy, dummy)\n",
    "        x_aug, l_rev, l_perm, l_warp = generate_ssl_batch(x_batch)\n",
    "        outputs_cls = ssl_model(x_aug, task='class_only', mask_ratio=0.0)\n",
    "        # print(l_rev)\n",
    "        l_rev = l_rev.to(\"cuda\")\n",
    "        l_perm = l_perm.to(\"cuda\")\n",
    "        l_warp = l_warp.to(\"cuda\")\n",
    "        _, _, loss_class = multitask_loss(outputs_cls, x_aug, l_rev, l_perm, l_warp)\n",
    "        loss = (weight[0] * loss_recon) + (weight[1] * loss_class)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_recon_loss += loss_recon.item()\n",
    "        total_class_loss += loss_class.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_recon = total_recon_loss / len(loader)\n",
    "    avg_class = total_class_loss / len(loader)    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS_SSL}] Total: {avg_loss:.4f} | Recon: {avg_recon:.4f} | Class: {avg_class:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d71992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Tests the trained model and prints the parameter count and final accuracy.\n",
    "    \"\"\"\n",
    "    print(f\"\\nNumber of model parameters is: {count_parameters(model)}\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_test = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred = np.append(y_pred, predicted.cpu().numpy())\n",
    "            y_test = np.append(y_test, labels.cpu().numpy())\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8194d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pre-trained SSL Weights...\n",
      "--- Setting Global Seed: 130 ---\n",
      "\n",
      "Phase 1: Linear Probing (Encoder Frozen)\n",
      "Epoch 1/3 | Loss: 1.3247 | Acc: 47.82%\n",
      "Epoch 2/3 | Loss: 1.1523 | Acc: 55.69%\n",
      "Epoch 3/3 | Loss: 1.0979 | Acc: 57.43%\n",
      "\n",
      "Phase 2: Full Fine-Tuning (Encoder Unfrozen)\n",
      "Epoch 1/3 | Loss: 0.8016 | Acc: 68.31%\n",
      "Epoch 2/3 | Loss: 0.5816 | Acc: 76.10%\n",
      "Epoch 3/3 | Loss: 0.4990 | Acc: 79.61%\n",
      "\n",
      "Number of model parameters is: 189253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6558732345849122\n",
      "--- Setting Global Seed: 427 ---\n",
      "\n",
      "Phase 1: Linear Probing (Encoder Frozen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.3256 | Acc: 48.14%\n",
      "Epoch 2/3 | Loss: 1.1635 | Acc: 55.00%\n",
      "Epoch 3/3 | Loss: 1.1149 | Acc: 56.31%\n",
      "\n",
      "Phase 2: Full Fine-Tuning (Encoder Unfrozen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 0.8022 | Acc: 67.86%\n",
      "Epoch 2/3 | Loss: 0.5965 | Acc: 75.28%\n",
      "Epoch 3/3 | Loss: 0.4959 | Acc: 79.49%\n",
      "\n",
      "Number of model parameters is: 189253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test).float()\n",
      "C:\\Users\\yizhou\\AppData\\Local\\Temp\\ipykernel_151820\\2505475813.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.611091973820186\n",
      "--- Setting Global Seed: 200 ---\n",
      "\n",
      "Phase 1: Linear Probing (Encoder Frozen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:233.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.3421 | Acc: 47.57%\n",
      "Epoch 2/3 | Loss: 1.1419 | Acc: 56.19%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPhase 1: Linear Probing (Encoder Frozen)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m optimizer_head = optim.Adam(model.fc.parameters(), lr=\u001b[32m0.001\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43mfine_tune_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPhase 2: Full Fine-Tuning (Encoder Unfrozen)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m model.unfreeze_encoder_weights()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mfine_tune_train\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device, epochs)\u001b[39m\n\u001b[32m     41\u001b[39m outputs = model(x_batch.transpose(\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m))\n\u001b[32m     42\u001b[39m loss = criterion(outputs, y_batch)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m optimizer.step()\n\u001b[32m     46\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yizhou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "class DownstreamClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps the pre-trained SSL model to perform classification.\n",
    "    Discards the Decoder and Pretext heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_model, num_classes, freeze_encoder=False):\n",
    "        super(DownstreamClassifier, self).__init__()\n",
    "        self.encoder = pretrained_model\n",
    "        # Create a new classification head\n",
    "        # The encoder outputs 128-dim pooled features\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "        if freeze_encoder:\n",
    "            self.freeze_encoder_weights()\n",
    "\n",
    "    def freeze_encoder_weights(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_encoder_weights(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We only use the 'downstream' task to get pooled features\n",
    "        features = self.encoder(x, task='downstream')\n",
    "        logits = self.fc(features)\n",
    "        return logits\n",
    "\n",
    "def fine_tune_train(model, loader, optimizer, criterion, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch.transpose(1,2))\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(loader):.4f} | Acc: {100 * correct / total:.2f}%\")\n",
    "seed = [130, 427, 200, 104, 110, 36, 503, 1028, 409, 1130]\n",
    "if __name__ == \"__main__\":\n",
    "    result = np.zeros((20, 4))\n",
    "    k = 0\n",
    "    for i in range(4):\n",
    "        X = [X1_test, X2_test, X3_test, X4_test]\n",
    "        y = [y1_test, y2_test, y3_test, y4_test]\n",
    "        X_test = X.pop(i)\n",
    "        y_test = y.pop(i)\n",
    "        X_train = torch.concatenate(X, axis = 0)\n",
    "        y_train = torch.concatenate(y, axis = 0)\n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # 2. Load Pre-trained Model\n",
    "        print(\"Loading Pre-trained SSL Weights...\")\n",
    "        ssl_model = MultiTaskResNet(in_channels=CHANNELS).to(device)\n",
    "        initial_state = copy.deepcopy(ssl_model.state_dict())\n",
    "        # 3. Initialize Fine-Tuning Model\n",
    "        NUM_CLASSES = 5\n",
    "        for j in range(5):\n",
    "            ssl_model.load_state_dict(initial_state)\n",
    "            set_seed(seed[j])\n",
    "            model = DownstreamClassifier(ssl_model, NUM_CLASSES, freeze_encoder=True).to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            class_counts = torch.bincount(y_train)\n",
    "            weights = 1. / class_counts.float()\n",
    "            weights = weights / weights.sum()\n",
    "            criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "            print(\"\\nPhase 1: Linear Probing (Encoder Frozen)\")\n",
    "            optimizer_head = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "            fine_tune_train(model, loader, optimizer_head, criterion, device, epochs=3)\n",
    "            print(\"\\nPhase 2: Full Fine-Tuning (Encoder Unfrozen)\")\n",
    "            model.unfreeze_encoder_weights()\n",
    "            optimizer_all = optim.Adam([\n",
    "                {'params': model.encoder.parameters(), 'lr': 1e-4}, # Low LR\n",
    "                {'params': model.fc.parameters(),      'lr': 1e-3}  # High LR\n",
    "            ])\n",
    "            fine_tune_train(model, loader, optimizer_all, criterion, device, epochs=3)\n",
    "            X_test = torch.tensor(X_test).float()\n",
    "            y_test = torch.tensor(y_test).long()\n",
    "            test_dataset = TensorDataset(X_test.transpose(1,2), y_test)\n",
    "            testloader = torch.utils.data.DataLoader(test_dataset\n",
    "                , batch_size=16,\n",
    "                shuffle=False, num_workers=4)\n",
    "            accuracy, precision, recall, f1 = test_model(model, testloader)\n",
    "            result[k, 0] = accuracy\n",
    "            result[k, 1] = precision\n",
    "            result[k, 2] = recall\n",
    "            result[k, 3] = f1\n",
    "            print(accuracy)\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd211752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67516362, 0.69141506, 0.67516362, 0.67552376],\n",
       "       [0.62831554, 0.63274176, 0.62831554, 0.62683534],\n",
       "       [0.64760592, 0.67468794, 0.64760592, 0.64913281],\n",
       "       [0.63107131, 0.65095831, 0.63107131, 0.62951672],\n",
       "       [0.60179125, 0.61721082, 0.60179125, 0.60028354],\n",
       "       [0.67280306, 0.67101782, 0.67280306, 0.66725203],\n",
       "       [0.66724557, 0.71641588, 0.66724557, 0.67554454],\n",
       "       [0.67176103, 0.6732993 , 0.67176103, 0.6690899 ],\n",
       "       [0.62348038, 0.66041742, 0.62348038, 0.62333217],\n",
       "       [0.67002431, 0.6691605 , 0.67002431, 0.65780479],\n",
       "       [0.55921856, 0.64853352, 0.55921856, 0.56452608],\n",
       "       [0.59259259, 0.63590892, 0.59259259, 0.58261039],\n",
       "       [0.60805861, 0.6208062 , 0.60805861, 0.60098188],\n",
       "       [0.58974359, 0.63552584, 0.58974359, 0.58547731],\n",
       "       [0.57102157, 0.66124576, 0.57102157, 0.56856745],\n",
       "       [0.64031079, 0.64667003, 0.64031079, 0.63508787],\n",
       "       [0.6179159 , 0.63678087, 0.6179159 , 0.61095958],\n",
       "       [0.67778793, 0.68604077, 0.67778793, 0.67250244],\n",
       "       [0.65722121, 0.65993177, 0.65722121, 0.65051363],\n",
       "       [0.66407678, 0.66632687, 0.66407678, 0.66243701]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28052bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6489262 , 0.66573248, 0.6489262 , 0.64743156])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427f6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01777658, 0.01905431, 0.01777658, 0.01766918])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "np.std(result, axis = 0)/np.sqrt(10   )*stats.t.ppf(0.975, df=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
